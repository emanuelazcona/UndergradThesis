{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning Methods for Predicting NBA Playoff Contention\n",
    "\n",
    "## Created by: Emanuel Azcona\n",
    "## Course: Introduction to Machine Learning & Senior Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries for handling dataframes, arrays, and generating the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from gen_data import gen_data\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF\n",
    "py.sign_in(username='emanuelazcona2022', api_key='mHqOmwUSmqFYjzMNuQVz')\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cumulative Player Databases\n",
    "\n",
    "First, we use our user-created function to develop two seperate dictionaries:\n",
    "\n",
    "- A dictionary of players by NBA Season\n",
    "- A dictionary of teams by NBA Season\n",
    "\n",
    "Each dictionary entry (in both dictionaries) is a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first year of NBA seasons we'd like to store\n",
    "start = 1\n",
    "# end year ....\n",
    "end = 16\n",
    "\n",
    "# returns two dictionaries:\n",
    "# 1. player dictionary where all NBA players are available in a dataframe, \n",
    "#       each dict. key is the NBA season's start year, ex: 2001 = 1, 2003 = 3\n",
    "# 2. team dictionary .....\n",
    "players, teams = gen_data(start,end)\n",
    "\n",
    "# store all the NBA years we used in a list\n",
    "play_years = list( players.keys() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dictionary of NBA Seasons with NBA teams\n",
    "\n",
    "Next, we create a dictionary of NBA seasons with each key referencing a dictionary of NBA teams for that respective season. Each entry of the teams dictionary has a dataframe of players on that team, in that year essentially.\n",
    "\n",
    "- NBA Season\n",
    "    - Team\n",
    "        - Players\n",
    "        \n",
    "Example:\n",
    "\n",
    "- '15-16'\n",
    "    - Oklahoma City Thunder (okl)\n",
    "        - Total Team Stats.\n",
    "        - Players & Player Stats.\n",
    "            - durant,kevin\n",
    "                - GP\n",
    "                - FGM\n",
    "                - etc..\n",
    "            - westbrook,russell\n",
    "                - GP\n",
    "                - FGM\n",
    "                - etc..\n",
    "            - etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create basketball team class which stores players for team and total team statistics\n",
    "class basketBallTeam:\n",
    "    def __init__(self, players):\n",
    "        self.players = players\n",
    "        totalStats = []\n",
    "\n",
    "# function for computing the overall team statistics of a team\n",
    "def computeTeamStats(currTeam, i):\n",
    "    \n",
    "    # sum up field goals made by all players\n",
    "    FGM = np.sum(currTeam[:,5])\n",
    "    \n",
    "    # sum up field goals attempted\n",
    "    FGA = np.sum(currTeam[:,6])\n",
    "    \n",
    "    # Three pointers made\n",
    "    TM = np.sum(currTeam[:,7])\n",
    "    \n",
    "    # Three pointers attempted\n",
    "    TA = np.sum(currTeam[:,8])\n",
    "    \n",
    "    # Free-throws made\n",
    "    FTM = np.sum(currTeam[:,9])\n",
    "    \n",
    "    # Free-throws attempted\n",
    "    FTA = np.sum(currTeam[:,10])\n",
    "    \n",
    "    # Offensive rebounds made\n",
    "    OR = np.sum(currTeam[:, 11])\n",
    "    \n",
    "    # Total rebounds made\n",
    "    TR = np.sum(currTeam[:,12])\n",
    "    \n",
    "    # Totals assist count\n",
    "    AS = np.sum(currTeam[:,13])\n",
    "    \n",
    "    # Total assists count\n",
    "    ST = np.sum(currTeam[:,14])\n",
    "    \n",
    "    # Total turnovers count\n",
    "    TO = np.sum(currTeam[:,15])\n",
    "    \n",
    "    # Total blocks count\n",
    "    BK = np.sum(currTeam[:,16])\n",
    "    \n",
    "    # Personal fouls count\n",
    "    PF = np.sum(currTeam[:,17])\n",
    "    \n",
    "    # Total points made\n",
    "    PTS = np.sum(currTeam[:,19])\n",
    "    \n",
    "    # Playoff\n",
    "    PLAY = bool(np.array(teams[year])[i,21])\n",
    "    \n",
    "    # MVP Status defaulted to 0\n",
    "    MVP = 0\n",
    "    \n",
    "    # Conference (0 for East, 1 for West)\n",
    "    CONF = 0\n",
    "    \n",
    "    # If MVP is found, \n",
    "    mvpArray = currTeam[:,23]\n",
    "    if True in mvpArray:\n",
    "        MVP = 1\n",
    "    \n",
    "    # If West is found,\n",
    "    if 'West' in currTeam[:,-2]:\n",
    "        CONF = 1\n",
    "    \n",
    "    # create list of teams stats\n",
    "    \"\"\" [Conference, Playoff, FGM, FG%, 3M, 3PT%, FTM, FT%, OR, REB%,\n",
    "         AS, ST, TO, BK, PF, PTS, MVP] \"\"\"\n",
    "    currTeamStats = [CONF, PLAY, FGM,float(FGM)/FGA, TM, float(TM)/TA\\\n",
    "                     , FTM,float(FTM)/FTA, OR, float(OR)/TR\\\n",
    "                     , AS, ST, TO, BK, PF, PTS, MVP]\n",
    "    return currTeamStats\n",
    "\n",
    "# create dictionary of NBA teams\n",
    "columns = ['Conference','Playoff', 'FGM', 'FG%'\\\n",
    "            ,'3M', '3PT%', 'FTM'\\\n",
    "            ,'FT%', 'OR', 'REB%'\\\n",
    "            ,'AS', 'ST', 'TO'\\\n",
    "            ,'BK', 'PF', 'PTS', 'MVP']\n",
    "\n",
    "# create empty dictionary of NBA Seasons\n",
    "nbaSeasons = {}\n",
    "\n",
    "# iterate through NBA seasons\n",
    "for year in play_years:\n",
    "    \n",
    "    # create lists of all team names for this year\n",
    "    teamNames = teams[year]['key'].tolist()\n",
    "    \n",
    "    # create empty dictionary of teams for this year\n",
    "    teamsDict = {}\n",
    "    for i, team in enumerate(teamNames):\n",
    "        \n",
    "        # initialize empty Team list\n",
    "        currTeam = []\n",
    "        \n",
    "        # grab all players for this current season\n",
    "        currPlaySeason = np.array( players[year] )\n",
    "        \n",
    "        # parse through all players in current season\n",
    "        for j in range(currPlaySeason.shape[0]):\n",
    "            \n",
    "            # if the current player's team is equal to the team we are creating\n",
    "            if(currPlaySeason[j,1] == team):\n",
    "                \n",
    "                # append all of their features as an element in the list\n",
    "                currTeam.append(currPlaySeason[j,:])\n",
    "        \n",
    "        # turn team list into a numpy array\n",
    "        currTeam = np.array(currTeam)\n",
    "        \n",
    "        # store current team as a dataframe in the dictionary of teams\n",
    "        teamsDict[team] = basketBallTeam(pd.DataFrame(currTeam\\\n",
    "                                                      , columns = players[play_years[0]].columns.tolist()))\n",
    "        \n",
    "        # compute total stats for current team\n",
    "        currTeamStats = computeTeamStats(currTeam, i)\n",
    "        \n",
    "        # add total stats as dataframe for current team\n",
    "        teamsDict[team].totalStats = pd.DataFrame(np.array([currTeamStats])\\\n",
    "                                                  , columns = columns)\n",
    "    \n",
    "    # store dictionary to NBA year\n",
    "    nbaSeasons[year] = teamsDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pandas DataFrames of All NBA Teams & All NBA Players\n",
    "\n",
    "Parsing through the nbaSeasons dictionary, we create a dataframe of every NBA player that's ever played in any NBA season. The same process is done for the teams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# boolean flag to indicate not to vertically stack but instead initialize a NumPy array\n",
    "flag = False\n",
    "for year in play_years:\n",
    "    # create lists of all team names for this year\n",
    "    teamNames = teams[year]['key'].tolist()\n",
    "    \n",
    "    # parse through team names\n",
    "    for team in teamNames:\n",
    "        \n",
    "        # if it's the first team, initialize numpy array\n",
    "        if(not flag):\n",
    "            flag = True\n",
    "            allTeamHist = np.array( nbaSeasons[year][team].totalStats )\n",
    "            allPlayHist = np.array( nbaSeasons[year][team].players )\n",
    "            continue\n",
    "        \n",
    "        # else vertically stack next few teams\n",
    "        allTeamHist = np.vstack( (allTeamHist, np.array(nbaSeasons[year][team].totalStats) ) )\n",
    "        allPlayHist = np.vstack( (allPlayHist, np.array(nbaSeasons[year][team].players) ) )\n",
    "\n",
    "# create columns labels for teams and players \n",
    "columnsTeam = columns\n",
    "columnsPlayers = players[play_years[0]].columns.tolist()\n",
    "\n",
    "# create all team dataframe\n",
    "allTeamHist = pd.DataFrame(allTeamHist, columns = columnsTeam)\n",
    "allTeamHist = allTeamHist.dropna()\n",
    "\n",
    "# create all player dataframe\n",
    "allPlayHist = pd.DataFrame(allPlayHist, columns = columnsPlayers )\n",
    "allPlayHist = allPlayHist.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze NBA Team Data\n",
    "### Task I: Overall NBA Team Statistics\n",
    "\n",
    "Let's take a deeper look into the NBA Team data and analyze relationships across seasons. First, we compile a dataframe of total integer stats and average fractional stats for each individual NBA team's franchise history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag = False\n",
    "for year in play_years:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        teamKeys = np.transpose( np.array( [teams[year]['key']] ) )\n",
    "        continue\n",
    "    teamKeys = np.vstack( (teamKeys, np.transpose( np.array( [teams[year]['key']] ) ) ) )\n",
    "\n",
    "# create a deep copy of allTeamHist in order to not manipulate or lose important data in allTeamHist\n",
    "X = np.array(deepcopy(allTeamHist)) \n",
    "X = pd.DataFrame(X, columns = columns, index = teamKeys.ravel())\n",
    "del X['Conference']\n",
    "del X['Playoff']\n",
    "del X['MVP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for computing overall sum of stats for each team (not by season but for entire NBA track starting in 2001)\n",
    "def computeOverallTeamStats(X, team, statNames):\n",
    "    overTeamStats = []\n",
    "    \n",
    "    # parse through stats you wish to compute for \n",
    "    for stat in statNames:\n",
    "        # append sum of those stats for the same team across all seasons\n",
    "        if stat in ['FG%', '3PT%', 'FT%', 'REB%']:\n",
    "            overTeamStats.append( X[X.index == team][stat].mean(axis = 0) )\n",
    "        else:\n",
    "            overTeamStats.append( X[X.index == team][stat].sum(axis = 0) )\n",
    "    return np.array(overTeamStats)\n",
    "\n",
    "# all stats we wish to compute overall sum for\n",
    "allStatNames = columnsTeam[2:-1]\n",
    "\n",
    "# create list of teams already checked\n",
    "teamsAlreadyChecked = []\n",
    "flag = False\n",
    "\n",
    "# parse through teams\n",
    "for team in list(X.index):\n",
    "    \n",
    "    # if the team was already checked, continue to the next team\n",
    "    if team in teamsAlreadyChecked:\n",
    "        continue\n",
    "    else:\n",
    "        teamsAlreadyChecked.append(team)\n",
    "        \n",
    "        # if the numpy matrix for the overall team stats hasn't been made, initialize it\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            # compute overall team stats for current team\n",
    "            overTeamStats = computeOverallTeamStats(X, team, allStatNames)\n",
    "            continue\n",
    "        # compute overall team stats for current team\n",
    "        currTeamStats = computeOverallTeamStats(X, team, allStatNames)\n",
    "        # vertically stack next team\n",
    "        overTeamStats = np.vstack( (overTeamStats, currTeamStats) )\n",
    "\n",
    "# create dataframe out of numpy array\n",
    "overTeamStatsDF = pd.DataFrame(overTeamStats, columns = allStatNames, index = teamsAlreadyChecked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we obtain the plot of all the integer stats to analyze the team's total sum of franchise stats. Using the Python library, plotly, we obtain an organized (and visually asthetic), multi-bar graph.\n",
    "\n",
    "- Integer Stats\n",
    "    - Field Goals Made (FGM)\n",
    "    - Three Pointers Made (3M)\n",
    "    - Free Throws Made (FTM)\n",
    "    - Offensive Rebounds (OR)\n",
    "    - Assists (AS)\n",
    "    - Steals (ST)\n",
    "    - Turnovers (TO)\n",
    "    - Blocks (BK)\n",
    "    - Personal Fouls (PF)\n",
    "    - Points Made (PTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain integer stat labels\n",
    "\n",
    "# turn keys for fractional stats into a list of keys\n",
    "intStats = overTeamStatsDF.columns.tolist()\n",
    "\n",
    "# fractional stat keys we wish to remove (non-integer stats)\n",
    "removeFields = ['FG%', '3PT%', 'FT%', 'REB%']\n",
    "\n",
    "# remove fractional stat keys\n",
    "for field in removeFields:\n",
    "    intStats.remove(field)\n",
    "\n",
    "# extract all integer data and create multicolumn barcharts of overall integer stats\n",
    "data = []\n",
    "for team in list(overTeamStatsDF.index):\n",
    "    teamStats = np.array(overTeamStatsDF[overTeamStatsDF.index == team]).ravel().tolist()\n",
    "    \n",
    "    \n",
    "    for fracLoc in [1, 2, 3, 4]:\n",
    "        teamStats.remove(teamStats[fracLoc])\n",
    "\n",
    "    # create bar chart traces for plotly chart\n",
    "    trace = go.Bar(\n",
    "        x = intStats,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Overall Total Sum of Team Integer Statistics (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'Integer Statistics'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Integer Score'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we plot the fractional stats the same manner we did the integer stats.\n",
    "\n",
    "- Fractional Stats\n",
    "    - Field Goal Percentage (FG%)\n",
    "    - Three Point Percentage (3PT%)\n",
    "    - Free Throw Percentage (FT%)\n",
    "    - Offensive Rebound Perentage (REB%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfuly sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~emanuelazcona2022/0 or inside your plot.ly account where it is named 'overall team integer features'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/0.embed\" height=\"800px\" width=\"1500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=1500 #width in pixels\n",
    "fig.layout.height = 800\n",
    "py.iplot(fig, filename = 'overall team integer features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain fractional stats (same as integer stats process)\n",
    "fracStats = overTeamStatsDF.columns.tolist()\n",
    "\n",
    "# integer stat keys we wish to remove\n",
    "removeFields = ['FGM', '3M', 'FTM', 'OR', 'AS', 'ST', 'TO', 'BK', 'PF', 'PTS']\n",
    "\n",
    "# remove integer stat keys and keep fractional stat keys\n",
    "for field in removeFields:\n",
    "    fracStats.remove(field)\n",
    "\n",
    "# repeat for fractional stats\n",
    "data = []\n",
    "for team in list(overTeamStatsDF.index):\n",
    "    teamStats = itemgetter(*[1,3,5,7])(np.array(\n",
    "        overTeamStatsDF[overTeamStatsDF.index == team]).ravel().tolist())\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = fracStats,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Overall Average of Team Fraction Statistics (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'Fractional Statistics'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Percentage Score'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/2.embed\" height=\"750px\" width=\"1500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=1500 #width in pixels\n",
    "fig.layout.height = 750\n",
    "py.iplot(fig, filename = 'overall team fractional features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze NBA Team Data\n",
    "### Task II: Analyze Individual NBA Team Statistics By Year\n",
    "For our next analysis, we want to observe the behavior of NBA teams through the different seasons in our dataset (2001-2002 through 2015-2016). First, we add the New Orleans teams to the first three seasons of our NBA dataset, with stats. of 0 across the board for all three years, since the New Orleans teams were not introduced until the 2004-2005 NBA Season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create deepcopy of X in order to not damage data\n",
    "Xarr = deepcopy(X)\n",
    "\n",
    "# convert to NumPy array\n",
    "Xarr = np.array(Xarr)\n",
    "\n",
    "# add NOrleans team with stats of 0 across the board for the first three seasons\n",
    "for i in range(3):\n",
    "    Xarr = np.vstack((np.array([0 for i in range(Xarr.shape[1])]), Xarr ))\n",
    "\n",
    "# reconvert back to dataframe with newly added NOrleans team stats\n",
    "XarrDF = pd.DataFrame(Xarr, columns = X.columns.tolist(), index = ['nor']*3 + X.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task I: Team Field Goals per Season\n",
    "Next, we construct our bar graph to analyze the performance of all NBA teams throughout each of the NBA seasons in our dataset. The first feature we analyze is the numebr of field goals a team makes in each NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract team years list where each entry is a string in the form of: 2001-2002\n",
    "teamYears = []\n",
    "for year in play_years:\n",
    "    teamYears.append(str(year + 2000) + '-' + str(year + 2001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot field goals\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['FGM']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Field Goals Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Number of Field Goals Made in Season'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/4.embed\" height=\"750px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 750\n",
    "py.iplot(fig, filename = 'field goals made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task II: Team Three Pointers per Season\n",
    "The folllowing feature we analyze is the number fo three-pointers a team scores in an season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot threes made\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['3M']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Threes Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Threes Made in a Season'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/6.embed\" height=\"750px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 750\n",
    "py.iplot(fig, filename = 'threes made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task III: Team Assists per Season\n",
    "Afterwards, we look closely at the number of assists per NBA season for each NBA team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot assists made per team\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['AS']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Assists per Teams per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Assists in a Season'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/8.embed\" height=\"750px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 750\n",
    "py.iplot(fig, filename = 'assists per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task IV: Points Scored per Season\n",
    "The next feature we analyze is the number of points a team scores in each NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot points scored per team\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['PTS']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Points Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Points Made in a Season'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/10.embed\" height=\"750px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 750\n",
    "py.iplot(fig, filename = 'points made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task V: Team Free-Throws Made per Season\n",
    "The next feature we analyze is the number of free-throws a team scores in each NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot free throws made per team\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['FTM']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Free-Throws Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Free-Throws Made in a Season'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/12.embed\" height=\"750px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 750\n",
    "py.iplot(fig, filename = 'free throws made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task VI: Team Steals per Season\n",
    "The next feature we analyze is the number of steals teams commit per season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot steals made per team\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['ST']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Steals Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Steals Made in a Season'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/14.embed\" height=\"750px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 750\n",
    "py.iplot(fig, filename = 'steals made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting NBA Playoff Teams\n",
    "## Sub-process I: Determining the Statistical Significance of Team Stats to Playoff Status\n",
    "For the first prediction, we will focus on predicting a whether an NBA team is cable of becoming a Playoff contender.\n",
    "\n",
    "In this initial step, we focus on determining the statistical significance of features to NBA-Playoff contention. First, we look for the index of every NBA team that has been in the NBA-Playoffs during their respective season and those that weren't and store these indices in seperate NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# record the indices of playoff teams, and non playoff teams\n",
    "\n",
    "Iplay = np.where( np.array(allTeamHist['Playoff']) == True )[0]\n",
    "Inon = np.where( np.array(allTeamHist['Playoff']) == False )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a deep copy of the allTeamHist dataframe, but remove irrelevant features such as:\n",
    "- Playoff Indication (Playoff)\n",
    "- Conference Indication (Conference)\n",
    "\n",
    "because this is what we're trying to predict. In other words, we remove the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag = False\n",
    "for year in play_years:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        teamNames = np.transpose( np.array( [teams[year]['team']] ) )\n",
    "        continue\n",
    "    teamNames = np.vstack( (teamNames, np.transpose( np.array( [teams[year]['team']] ) ) ) )\n",
    "X = np.hstack( ( teamNames, np.array(deepcopy(allTeamHist)) ) )\n",
    "X = pd.DataFrame(X, columns = [\"Team\"] + columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Playoff</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3M</th>\n",
       "      <th>3PT%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OR</th>\n",
       "      <th>REB%</th>\n",
       "      <th>AS</th>\n",
       "      <th>ST</th>\n",
       "      <th>TO</th>\n",
       "      <th>BK</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>MVP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AtlantaHawks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2903</td>\n",
       "      <td>0.43905</td>\n",
       "      <td>423</td>\n",
       "      <td>0.354271</td>\n",
       "      <td>1487</td>\n",
       "      <td>0.765311</td>\n",
       "      <td>955</td>\n",
       "      <td>0.280717</td>\n",
       "      <td>1656</td>\n",
       "      <td>667</td>\n",
       "      <td>1204</td>\n",
       "      <td>350</td>\n",
       "      <td>1703</td>\n",
       "      <td>7716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BostonCeltics</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3085</td>\n",
       "      <td>0.425517</td>\n",
       "      <td>759</td>\n",
       "      <td>0.359545</td>\n",
       "      <td>1580</td>\n",
       "      <td>0.771108</td>\n",
       "      <td>976</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>1746</td>\n",
       "      <td>820</td>\n",
       "      <td>1136</td>\n",
       "      <td>301</td>\n",
       "      <td>1886</td>\n",
       "      <td>8509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CharlotteHornets</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2893</td>\n",
       "      <td>0.439666</td>\n",
       "      <td>346</td>\n",
       "      <td>0.348089</td>\n",
       "      <td>1568</td>\n",
       "      <td>0.744893</td>\n",
       "      <td>1059</td>\n",
       "      <td>0.297138</td>\n",
       "      <td>1759</td>\n",
       "      <td>653</td>\n",
       "      <td>1108</td>\n",
       "      <td>456</td>\n",
       "      <td>1746</td>\n",
       "      <td>7700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChicagoBulls</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2458</td>\n",
       "      <td>0.441372</td>\n",
       "      <td>280</td>\n",
       "      <td>0.348259</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.734036</td>\n",
       "      <td>670</td>\n",
       "      <td>0.248148</td>\n",
       "      <td>1498</td>\n",
       "      <td>493</td>\n",
       "      <td>973</td>\n",
       "      <td>329</td>\n",
       "      <td>1597</td>\n",
       "      <td>6311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ClevelandCavaliers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2948</td>\n",
       "      <td>0.447888</td>\n",
       "      <td>387</td>\n",
       "      <td>0.377193</td>\n",
       "      <td>1529</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>968</td>\n",
       "      <td>0.280498</td>\n",
       "      <td>1891</td>\n",
       "      <td>572</td>\n",
       "      <td>1129</td>\n",
       "      <td>470</td>\n",
       "      <td>1752</td>\n",
       "      <td>7812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DallasMavericks</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3660</td>\n",
       "      <td>0.461248</td>\n",
       "      <td>687</td>\n",
       "      <td>0.381032</td>\n",
       "      <td>1730</td>\n",
       "      <td>0.800185</td>\n",
       "      <td>946</td>\n",
       "      <td>0.259391</td>\n",
       "      <td>2219</td>\n",
       "      <td>623</td>\n",
       "      <td>1071</td>\n",
       "      <td>520</td>\n",
       "      <td>1925</td>\n",
       "      <td>9737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Team Conference Playoff   FGM       FG%   3M      3PT%   FTM  \\\n",
       "0        AtlantaHawks          0       0  2903   0.43905  423  0.354271  1487   \n",
       "1       BostonCeltics          0       1  3085  0.425517  759  0.359545  1580   \n",
       "2    CharlotteHornets          0       1  2893  0.439666  346  0.348089  1568   \n",
       "3        ChicagoBulls          0       0  2458  0.441372  280  0.348259  1115   \n",
       "4  ClevelandCavaliers          0       0  2948  0.447888  387  0.377193  1529   \n",
       "5     DallasMavericks          1       1  3660  0.461248  687  0.381032  1730   \n",
       "\n",
       "        FT%    OR      REB%    AS   ST    TO   BK    PF   PTS MVP  \n",
       "0  0.765311   955  0.280717  1656  667  1204  350  1703  7716   0  \n",
       "1  0.771108   976  0.268353  1746  820  1136  301  1886  8509   0  \n",
       "2  0.744893  1059  0.297138  1759  653  1108  456  1746  7700   0  \n",
       "3  0.734036   670  0.248148  1498  493   973  329  1597  6311   0  \n",
       "4  0.772222   968  0.280498  1891  572  1129  470  1752  7812   0  \n",
       "5  0.800185   946  0.259391  2219  623  1071  520  1925  9737   0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only plot the first 6 rows of teams to save computation and plotting time (takes very long to plot ALL teams)\n",
    "\n",
    "# allNBATeamsTable = FF.create_table(X.head(6))\n",
    "# allNBATeamsTable.layout.width=2500 #width in pixels\n",
    "# allNBATeamsTable.layout.margin.update({'t':75, 'l':50})\n",
    "# allNBATeamsTable.layout.update({'title': 'All NBA Team Statistics (First 6)'})\n",
    "# py.iplot(allNBATeamsTable, filename = 'All NBA Team Stats')\n",
    "X.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X['Team']\n",
    "del X['Playoff']\n",
    "del X['Conference']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we import the ztest function from the Python statsmodel.stats.weightstats module to perform a Z-test on our features. We do this to determine the significance of our features in the determination of the NBA-Playoff contenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute Z-Test on all features and compute statistical significance of each feature\n",
    "\n",
    "statDF = []\n",
    "for label in X.columns.tolist():\n",
    "    play = np.array(X[label])[Iplay]\n",
    "    non = np.array(X[label])[Inon]\n",
    "    stat, pval = ztest(play, non)\n",
    "    statDF.append( [label, stat, pval] )\n",
    "    \n",
    "statDF = pd.DataFrame(statDF, columns = ['Feature', 'statistic', 'p-val'])\n",
    "statDF = statDF.sort_values (['p-val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p-val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FG%</td>\n",
       "      <td>8.768354</td>\n",
       "      <td>1.812971e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AS</td>\n",
       "      <td>8.384611</td>\n",
       "      <td>5.089396e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PTS</td>\n",
       "      <td>7.405338</td>\n",
       "      <td>1.308170e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGM</td>\n",
       "      <td>6.609486</td>\n",
       "      <td>3.856556e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ST</td>\n",
       "      <td>6.408128</td>\n",
       "      <td>1.473176e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3PT%</td>\n",
       "      <td>6.251027</td>\n",
       "      <td>4.077616e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3M</td>\n",
       "      <td>5.573980</td>\n",
       "      <td>2.489848e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>REB%</td>\n",
       "      <td>-5.208846</td>\n",
       "      <td>1.900186e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BK</td>\n",
       "      <td>5.141859</td>\n",
       "      <td>2.720336e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FTM</td>\n",
       "      <td>4.598369</td>\n",
       "      <td>4.258115e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MVP</td>\n",
       "      <td>3.706515</td>\n",
       "      <td>2.101306e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FT%</td>\n",
       "      <td>1.201629</td>\n",
       "      <td>2.295072e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TO</td>\n",
       "      <td>-0.700429</td>\n",
       "      <td>4.836597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PF</td>\n",
       "      <td>-0.473659</td>\n",
       "      <td>6.357433e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OR</td>\n",
       "      <td>-0.015381</td>\n",
       "      <td>9.877282e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  statistic         p-val\n",
       "1      FG%   8.768354  1.812971e-18\n",
       "8       AS   8.384611  5.089396e-17\n",
       "13     PTS   7.405338  1.308170e-13\n",
       "0      FGM   6.609486  3.856556e-11\n",
       "9       ST   6.408128  1.473176e-10\n",
       "3     3PT%   6.251027  4.077616e-10\n",
       "2       3M   5.573980  2.489848e-08\n",
       "7     REB%  -5.208846  1.900186e-07\n",
       "11      BK   5.141859  2.720336e-07\n",
       "4      FTM   4.598369  4.258115e-06\n",
       "14     MVP   3.706515  2.101306e-04\n",
       "5      FT%   1.201629  2.295072e-01\n",
       "10      TO  -0.700429  4.836597e-01\n",
       "12      PF  -0.473659  6.357433e-01\n",
       "6       OR  -0.015381  9.877282e-01"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tabulate results of Z-Test\n",
    "\n",
    "# allTeamsZtestTable = FF.create_table(statDF)\n",
    "# allTeamsZtestTable.layout.width = 600\n",
    "# allTeamsZtestTable.layout.margin.update({'t':75, 'l':50})\n",
    "# allTeamsZtestTable.layout.update({'title': 'Features Statistical Significance'})\n",
    "# py.iplot(allTeamsZtestTable, filename = 'Feat Stat Sig')\n",
    "\n",
    "statDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis shows that features such as:\n",
    "- Offensive Rebounding Percentage (REB%)\n",
    "- Personal Fouls (PF)\n",
    "- Turnovers (TO)\n",
    "- Offensive Rebounds (OR)\n",
    "- Free Throw Percentage (FT%)\n",
    "\n",
    "do not have a real significance in the determination of the NBA-Playoff contention. Therefore, we remove these features from our feature matrix since they probabilistically reject our null hypothesis. Therefore, our most significant performance attributes (in order from most important down) are:\n",
    "- Field Goal Percentage (FG%)\n",
    "- Assists (AS)\n",
    "- Points (PTS)\n",
    "- Field Goals Made (FGM)\n",
    "- Steals (ST)\n",
    "- Three Point Percentage (3PT%)\n",
    "- Threes Made (3M)\n",
    "- Blocks (BK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X['REB%']\n",
    "del X['PF']\n",
    "del X['TO']\n",
    "del X['OR']\n",
    "del X['FT%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process II: Developing Training Data\n",
    "Now, we prepare a vector of boolean values indicating whether a team was an NBA-Playoff contender or not. We also cast the dataframe of predictors we have to a NumPy array type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelazcona/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning:\n",
      "\n",
      "Data with input dtype object was converted to float64 by the scale function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = list( deepcopy(allTeamHist['Playoff']) )\n",
    "Xs = preprocessing.scale(np.array(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Task I: Train Classifier on Entire Dataset\n",
    "Next, we develop a logistic classifier model using sklearn to predict NBA Playoff Contenders. First we train our logistic regression classifier on all of the NBA teams that have ever existed. Using this, we test out a range of regularization strengths, $C$, to determine what the best one is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cvals = np.logspace(-2,6,20)\n",
    "C_max = [None for _ in range(3)]\n",
    "\n",
    "\n",
    "# initialize minimum error rate of 100%\n",
    "acc_max = [0 for _ in range(3)]\n",
    "accLog = [[] for _ in range(3)]\n",
    "\n",
    "y_hat = [None for _ in range(3)]\n",
    "\n",
    "logReg = [None for _ in range(3)]\n",
    "\n",
    "# parse through C values, train the logistic classifier for each C value, and compute the error rate of the model\n",
    "# for the corresponding C value\n",
    "for Cl1, Cl2, C in zip(Cvals, Cvals, Cvals):\n",
    "    \n",
    "    # create instance of logistic classifier (l1-penalized, l2-penalized, and unregularized)\n",
    "    logReg[0] = linear_model.LogisticRegression(penalty = 'l1', C = Cl1)\n",
    "    logReg[1] = linear_model.LogisticRegression(penalty = 'l2', C = Cl2)\n",
    "    logReg[2] = linear_model.LogisticRegression(C = C)\n",
    "    \n",
    "    # train model with training data\n",
    "    for i in range(3):\n",
    "        logReg[i].fit(Xs, y)\n",
    "        y_hat[i] = logReg[i].predict(Xs)\n",
    "        accLog[i].append( np.mean(y_hat[i] == y)*100 )\n",
    "        \n",
    "        if (acc_max[i] < accLog[i][-1]):\n",
    "            acc_max[i] = accLog[i][-1]\n",
    "            \n",
    "            if i is 0:\n",
    "                C_max[i] = Cl1\n",
    "            elif i is 1:\n",
    "                C_max[i] = Cl2\n",
    "            else:\n",
    "                C_max[i] = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_l1_log = np.transpose( np.array([accLog[0]]) )\n",
    "acc_l2_log = np.transpose( np.array([accLog[1]]) )\n",
    "acc_log = np.transpose( np.array([accLog[2]]) )\n",
    "Cvals = np.transpose( np.array([Cvals]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reg. Strength, $C$</th>\n",
       "      <th>$\\ell_1$ Acc., %</th>\n",
       "      <th>$\\ell_2$ Acc., %</th>\n",
       "      <th>Un-norm. Acc., %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>46.308725</td>\n",
       "      <td>71.812081</td>\n",
       "      <td>71.812081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026367</td>\n",
       "      <td>70.469799</td>\n",
       "      <td>72.930649</td>\n",
       "      <td>72.930649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069519</td>\n",
       "      <td>71.140940</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183298</td>\n",
       "      <td>73.601790</td>\n",
       "      <td>72.930649</td>\n",
       "      <td>72.930649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.483293</td>\n",
       "      <td>72.706935</td>\n",
       "      <td>72.930649</td>\n",
       "      <td>72.930649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.274275</td>\n",
       "      <td>73.601790</td>\n",
       "      <td>73.154362</td>\n",
       "      <td>73.154362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.359818</td>\n",
       "      <td>73.154362</td>\n",
       "      <td>73.154362</td>\n",
       "      <td>73.154362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.858668</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.357215</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61.584821</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>162.377674</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>428.133240</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1128.837892</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2976.351442</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7847.599704</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20691.380811</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>54555.947812</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>143844.988829</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>379269.019073</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "      <td>73.378076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Reg. Strength, $C$  $\\ell_1$ Acc., %  $\\ell_2$ Acc., %  Un-norm. Acc., %\n",
       "0             0.010000         46.308725         71.812081         71.812081\n",
       "1             0.026367         70.469799         72.930649         72.930649\n",
       "2             0.069519         71.140940         73.378076         73.378076\n",
       "3             0.183298         73.601790         72.930649         72.930649\n",
       "4             0.483293         72.706935         72.930649         72.930649\n",
       "5             1.274275         73.601790         73.154362         73.154362\n",
       "6             3.359818         73.154362         73.154362         73.154362\n",
       "7             8.858668         73.378076         73.378076         73.378076\n",
       "8            23.357215         73.378076         73.378076         73.378076\n",
       "9            61.584821         73.378076         73.378076         73.378076\n",
       "10          162.377674         73.378076         73.378076         73.378076\n",
       "11          428.133240         73.378076         73.378076         73.378076\n",
       "12         1128.837892         73.378076         73.378076         73.378076\n",
       "13         2976.351442         73.378076         73.378076         73.378076\n",
       "14         7847.599704         73.378076         73.378076         73.378076\n",
       "15        20691.380811         73.378076         73.378076         73.378076\n",
       "16        54555.947812         73.378076         73.378076         73.378076\n",
       "17       143844.988829         73.378076         73.378076         73.378076\n",
       "18       379269.019073         73.378076         73.378076         73.378076\n",
       "19      1000000.000000         73.378076         73.378076         73.378076"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accTable = pd.DataFrame( np.hstack((Cvals, acc_l1_log, acc_l2_log, acc_log))\\\n",
    "                                            , columns = ['Reg. Strength, $C$'\n",
    "                                                         , '$\\ell_1$ Acc., %'\\\n",
    "                                                         , '$\\ell_2$ Acc., %'\\\n",
    "                                                         , 'Un-norm. Acc., %'])\n",
    "\n",
    "# totAccTable = FF.create_table(accTable)\n",
    "\n",
    "# totAccTable.layout.width = 1e3\n",
    "# totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "# totAccTable.layout.update({'title': 'Accuracy of Logistic Regression, Regularization Strengths on Total-Train Total-Predict Model'})\n",
    "# py.iplot(totAccTable, filename = 'logRegCAccTable')\n",
    "accTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18329807108324356, 0.069519279617756058, 0.069519279617756058]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accTable.to_csv(\"logRegCAccuracy.csv\", encoding='utf-8', index = False)\n",
    "C_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our analysis, we keep the regularization strength, $C$, which minimizes the error in predicting the NBA-Playoff contenders for all three of our models.\n",
    "\n",
    "Now, we test our trained model to predict NBA-Playoff contenders in each NBA season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Task II: Use Entire-Trained-Classifier to Predict Playoffs in Each NBA Season\n",
    "Using the regularization strength, $C$, with the least error in predicting the NBA-Playoff contender, we now use our traiend classifier to predict Playoff teams in each individual NBA Season, by iterating through each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that seperates top NBA teams so that there are 8 Eastern & 8 Western Playoff teams\n",
    "def sepPredTeamsToEastAndWest(predTeams, eastTeams, westTeams):\n",
    "    west, westPredict = 0, []\n",
    "    east, eastPredict = 0, []\n",
    "    \n",
    "    # parse through predicted teams\n",
    "    for team in predTeams:\n",
    "        if team in westTeams and west < 8:\n",
    "            west += 1\n",
    "            westPredict.append(team)\n",
    "            continue\n",
    "        if team in eastTeams and east < 8:\n",
    "            east += 1\n",
    "            eastPredict.append(team)\n",
    "            continue\n",
    "    return eastPredict, westPredict\n",
    "\n",
    "# function for computing accuracy of prediction\n",
    "def computeAccForPredict(eastPredict, eastTruth, westPredict, westTruth):\n",
    "    # to ensure that we do not have more than 8 teams per conference\n",
    "    west = 0\n",
    "    east = 0\n",
    "    \n",
    "    # intialize number of correct predictions to 0\n",
    "    corr = 0\n",
    "    for eastTeam, westTeam in zip(eastPredict, westPredict):\n",
    "        \n",
    "        if westTeam in westTruth and west < 8:\n",
    "            west += 1\n",
    "            corr += 1\n",
    "        if eastTeam in eastTruth and east < 8:\n",
    "            east += 1\n",
    "            corr += 1\n",
    "            \n",
    "    return float(corr)/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use logistic classifier that predicts with minimal error to predict playoff contenders per season, with\n",
    "# training data from all the previous seasons before the testing set\n",
    "\n",
    "logReg[0] = linear_model.LogisticRegression(penalty = 'l1', C = C_max[0])\n",
    "logReg[1] = linear_model.LogisticRegression(penalty = 'l2', C = C_max[1])\n",
    "logReg[2] = linear_model.LogisticRegression(C = C_max[2])\n",
    "\n",
    "for i in range(3):\n",
    "    logReg[i].fit(Xs,y)\n",
    "\n",
    "accLog = [[] for _ in range(3)]\n",
    "acc_l1_log = []\n",
    "acc_l2_log = []\n",
    "acc_log = []\n",
    "\n",
    "for year in play_years:\n",
    "    currSeason = nbaSeasons[year]\n",
    "    teamNames = teams[year]['key']\n",
    "    \n",
    "    flag = False\n",
    "    for team in teamNames:\n",
    "        if(not flag):\n",
    "            flag = True\n",
    "            teamArr = np.array(currSeason[team].totalStats)\n",
    "            continue\n",
    "        teamArr = np.vstack((teamArr,np.array(currSeason[team].totalStats)))\n",
    "    \n",
    "    # Create training data for current year\n",
    "    X = pd.DataFrame(teamArr, columns = columns)\n",
    "    \n",
    "    # copy expected output values\n",
    "    y = list(deepcopy(X['Playoff']))\n",
    "    \n",
    "    # labels to delete, uneccesary for data fitting\n",
    "    del_labels = ['REB%', 'PF', 'TO', 'OR', 'FT%', 'Playoff', 'Conference']\n",
    "    for label in del_labels:\n",
    "        del X[label]\n",
    "    \n",
    "    # scale/normalize X\n",
    "    Xts = preprocessing.scale(X)\n",
    "    \n",
    "    # predict y\n",
    "    y_hat_l1 = logReg[0].predict_proba(Xts)\n",
    "    y_hat_l2 = logReg[1].predict_proba(Xts)\n",
    "    y_hat = logReg[2].predict_proba(Xts)\n",
    "    \n",
    "    # find indices of expected Playoff teams\n",
    "    playOffIndices = np.where(np.array(y) == True)\n",
    "    \n",
    "    teamNames = teams[year]['team']\n",
    "    \n",
    "    # determine names for Western Conference teams\n",
    "    westTeams = list(np.where(teams[year]['Conference'] == 'West')[0])\n",
    "    westTeamNames = list(np.array(teamNames)[westTeams])\n",
    "\n",
    "    # of those Western conference teams, create a list of the 8 Western Playoff teams\n",
    "    temp = []\n",
    "    westPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for i in westPlayOffIndices:\n",
    "        if i in westTeams:\n",
    "            temp.append(i)\n",
    "    westPlayOffIndices = temp[:]\n",
    "    westPlayoffTeams = np.array(teamNames)[westPlayOffIndices]\n",
    "    \n",
    "    # repeat for Eastern Conference teams\n",
    "    eastTeams = list(np.where(teams[year]['Conference'] == 'East')[0])\n",
    "    eastTeamNames = list(np.array(teamNames)[eastTeams])\n",
    "    \n",
    "    temp = []\n",
    "    eastPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for i in eastPlayOffIndices:\n",
    "        if i in eastTeams:\n",
    "            temp.append(i)\n",
    "    eastPlayOffIndices = temp[:]\n",
    "    eastPlayoffTeams = np.array(teamNames)[eastPlayOffIndices]\n",
    "    \n",
    "    \n",
    "    # seperate top 8 predicted Eastern Teams, and top 8 predicted Western Teams\n",
    "    sortedPlayPred_l1 = np.argsort(y_hat_l1[:,1])\n",
    "    predictedTeams_l1 = np.array(teamNames)[sortedPlayPred_l1[-1::-1]]\n",
    "    eastPredictTeams_l1, westPredictTeams_l1 =\\\n",
    "        sepPredTeamsToEastAndWest(predictedTeams_l1, eastTeamNames, westTeamNames)\n",
    "        \n",
    "    # repeat for l2-normalized classifier\n",
    "    sortedPlayPred_l2 = np.argsort(y_hat_l2[:,1])\n",
    "    predictedTeams_l2 = np.array(teamNames)[sortedPlayPred_l2[-1::-1]]\n",
    "    eastPredictTeams_l2, westPredictTeams_l2 =\\\n",
    "        sepPredTeamsToEastAndWest(predictedTeams_l2, eastTeamNames, westTeamNames)\n",
    "    \n",
    "    # repeat for unnormalized classifier\n",
    "    sortedPlayPred = np.argsort(y_hat[:,1])\n",
    "    predictedTeams = np.array(teamNames)[sortedPlayPred[-1::-1]]\n",
    "    eastPredictTeams, westPredictTeams =\\\n",
    "        sepPredTeamsToEastAndWest(predictedTeams, eastTeamNames, westTeamNames)\n",
    "    \n",
    "    acc_i_l1 = computeAccForPredict(eastPredictTeams_l1\\\n",
    "                                   , eastPlayoffTeams\\\n",
    "                                   , westPredictTeams_l1\\\n",
    "                                   , westPlayoffTeams)\n",
    "    \n",
    "    acc_i_l2 = computeAccForPredict(eastPredictTeams_l2\\\n",
    "                                   , eastPlayoffTeams\\\n",
    "                                   , westPredictTeams_l2\\\n",
    "                                   , westPlayoffTeams)\n",
    "    \n",
    "    acc_i = computeAccForPredict(eastPredictTeams\\\n",
    "                                   , eastPlayoffTeams\\\n",
    "                                   , westPredictTeams\\\n",
    "                                   , westPlayoffTeams)\n",
    "    \n",
    "    acc_l1_log.append(acc_i_l1*100)\n",
    "    acc_l2_log.append(acc_i_l2*100)\n",
    "    acc_log.append(acc_i*100)\n",
    "    \n",
    "    accLog[0].append(acc_i_l1*100)\n",
    "    accLog[1].append(acc_i_l2*100)\n",
    "    accLog[2].append(acc_i*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using, our predictions and ground truth data, we tabulate the accuracy of our entire-dataset-trained classifier for predicting the NBA-Playoff teams in each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create NumPy array of team years and accuracies in order to horizontally stack them\n",
    "playYearsString = np.transpose( np.array([teamYears]) )\n",
    "\n",
    "acc_l1_log = np.transpose( np.array([acc_l1_log]) )\n",
    "acc_l2_log = np.transpose( np.array([acc_l2_log]) )\n",
    "acc_log = np.transpose( np.array([acc_log]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NBA Season</th>\n",
       "      <th>$\\ell_1$ Acc., %</th>\n",
       "      <th>$\\ell_2$ Acc., %</th>\n",
       "      <th>Un-normalized Acc., %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-2002</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-2003</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-2004</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-2005</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-2006</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006-2007</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-2008</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008-2009</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-2010</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-2011</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2011-2012</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012-2013</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-2014</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-2015</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NBA Season $\\ell_1$ Acc., % $\\ell_2$ Acc., % Un-normalized Acc., %\n",
       "0   2001-2002             87.5             87.5                  87.5\n",
       "1   2002-2003             87.5             87.5                  87.5\n",
       "2   2003-2004             87.5             87.5                  87.5\n",
       "3   2004-2005             75.0             75.0                  75.0\n",
       "4   2005-2006            68.75            68.75                 68.75\n",
       "5   2006-2007             87.5             87.5                  87.5\n",
       "6   2007-2008            68.75            68.75                 68.75\n",
       "7   2008-2009             75.0             75.0                  75.0\n",
       "8   2009-2010            68.75            68.75                 68.75\n",
       "9   2010-2011             75.0             75.0                  75.0\n",
       "10  2011-2012            81.25            81.25                 81.25\n",
       "11  2012-2013            81.25            81.25                 81.25\n",
       "12  2013-2014            81.25            81.25                 81.25\n",
       "13  2014-2015             87.5             87.5                  87.5\n",
       "14  2015-2016             62.5             62.5                  62.5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accTable = pd.DataFrame( np.hstack((playYearsString, acc_l1_log, acc_l2_log, acc_log))\\\n",
    "                                            , columns = ['NBA Season'\n",
    "                                                         , '$\\ell_1$ Acc., %'\\\n",
    "                                                         , '$\\ell_2$ Acc., %'\\\n",
    "                                                         , 'Un-normalized Acc., %'])\n",
    "\n",
    "# totAccTable = FF.create_table(accTable)\n",
    "\n",
    "# totAccTable.layout.width = 800\n",
    "# totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "# totAccTable.layout.update({'title': 'Accuracy of Total-Trained Model Over Each NBA Season'})\n",
    "# py.iplot(totAccTable, filename = 'totAccTable')\n",
    "\n",
    "accTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Focus III: Create Dictionary of NBA Team Stats by Season\n",
    "Next, we create a dictionary of NBA teams by the season, with each entry being the a dataframe of seasonal stats for a team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create ordered dictionary of NBA stats by season\n",
    "teamsDict = OrderedDict()\n",
    "for year in play_years:\n",
    "    flag = False\n",
    "    seasonTeams = []\n",
    "    for team in teams[year]['key']:\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            seasonTeams = np.array(nbaSeasons[year][team].totalStats).ravel()\n",
    "            continue\n",
    "        seasonTeams = np.vstack( (seasonTeams, np.array(nbaSeasons[year][team].totalStats).ravel()) )\n",
    "    \n",
    "    seasonTeams = pd.DataFrame( seasonTeams, columns = columnsTeam, index = teams[year]['key'].ravel().tolist() )\n",
    "    \n",
    "    # delete irrelevant features as described by the Z-Test\n",
    "    del seasonTeams['REB%']\n",
    "    del seasonTeams['PF']\n",
    "    del seasonTeams['TO']\n",
    "    del seasonTeams['OR']\n",
    "    del seasonTeams['FT%']\n",
    "    del seasonTeams['Conference']\n",
    "    teamsDict[year] = seasonTeams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Focus IV: Train Classifier With All Years of NBA Team Data Prior to Each Season\n",
    "In this focus area, we create two lists:\n",
    "- Training Data List\n",
    "- Testing Data List\n",
    "\n",
    "The list organization is described by the following example:\n",
    "Ex:\n",
    "- Testing on 2013-2014 NBA Season\n",
    "    - Training Data contains all team information from 2001-2013\n",
    "    - Testing Data contains all team information for 2013-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileTrainData(teamsDict, year):\n",
    "    flag = False\n",
    "    for i in range(1,year+1):\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            Xtr = np.array(teamsDict[i])\n",
    "            continue\n",
    "        Xtr = np.vstack( (Xtr, np.array(teamsDict[i]) ) )\n",
    "    return Xtr\n",
    "    \n",
    "trainingFeatureSets = []\n",
    "trainingTargetSets = []\n",
    "for year in play_years[:-1]:\n",
    "    Xtr = compileTrainData(teamsDict, year)\n",
    "    ytr = deepcopy(Xtr[:,0])\n",
    "    Xtr = Xtr[:,1:]\n",
    "    \n",
    "    trainingFeatureSets.append(preprocessing.scale(Xtr))\n",
    "    trainingTargetSets.append(ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Focus V: Predict NBA Playoff Contenders in Each Season & Determine Accuracy\n",
    "Next, we use our trained model to predict NBA-Playoff contenders in each NBA season and compute the accuracy of our prediction for each season. Afterwards, we tabulate our results to analyze the relationship between progressively training the model with more data each season and predicting NBA-Playoff contenders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accLog = [[] for _ in range(3)]\n",
    "trainTime = [[] for _ in range(3)]\n",
    "predTime = [[] for _ in range(3)]\n",
    "\n",
    "acc_i = [None for _ in range(3)]\n",
    "logReg = [None for _ in range(3)]\n",
    "yts_hat = [None for _ in range(3)]\n",
    "\n",
    "predictedTeams = [None for _ in range(3)]\n",
    "sortedPlayPred = [None for _ in range(3)]\n",
    "\n",
    "eastPredictTeams = [None for _ in range(3)]\n",
    "westPredictTeams = [None for _ in range(3)]\n",
    "\n",
    "for i, year in enumerate(play_years[1:]):\n",
    "    Xts = np.array(teamsDict[year])\n",
    "    yts = deepcopy(Xts[:,0])\n",
    "    Xts =  preprocessing.scale(Xts[:,1:])\n",
    "    \n",
    "    for j in range(3):\n",
    "        if j in [0,1]:\n",
    "            if j is 0:\n",
    "                pen = 'l1'\n",
    "            elif j is 1:\n",
    "                pen = 'l2'\n",
    "            logReg[j] = linear_model.LogisticRegression(penalty = pen, C = C_max[j])\n",
    "        else:\n",
    "            logReg[j] = linear_model.LogisticRegression(C = C_max[j])\n",
    "        startTime = time()\n",
    "        logReg[j].fit (trainingFeatureSets[i], trainingTargetSets[i])\n",
    "        trainTime[j].append( (time() - startTime)*1e6 )\n",
    "        \n",
    "        startTime = time()\n",
    "        yts_hat[j] = logReg[j].predict_proba(Xts)\n",
    "        predTime[j].append( (time() - startTime)*1e6 )\n",
    "    \n",
    "    playOffIndices = np.where(np.array(yts) == True)\n",
    "    \n",
    "    westTeams = list(np.where(teams[year]['Conference'] == 'West')[0])\n",
    "    westTeamNames = list(np.array(teams[year]['team'])[westTeams])\n",
    "\n",
    "    temp = []\n",
    "    westPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for j in westPlayOffIndices:\n",
    "        if j in westTeams:\n",
    "            temp.append(j)\n",
    "    westPlayOffIndices = temp[:]\n",
    "    westPlayoffTeams = np.array(teams[year]['team'])[westPlayOffIndices]\n",
    "    \n",
    "    eastTeams = list(np.where(teams[year]['Conference'] == 'East')[0])\n",
    "    eastTeamNames = list(np.array(teams[year]['team'])[eastTeams])\n",
    "    \n",
    "    temp = []\n",
    "    eastPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for j in eastPlayOffIndices:\n",
    "        if j in eastTeams:\n",
    "            temp.append(j)\n",
    "    eastPlayOffIndices = temp[:]\n",
    "    eastPlayoffTeams = np.array(teams[year]['team'])[eastPlayOffIndices]\n",
    "    \n",
    "    for j in range(3):\n",
    "        sortedPlayPred[j] = np.argsort(yts_hat[j][:,1])\n",
    "        predictedTeams[j] = np.array(teams[year]['team'])[sortedPlayPred[j][-1::-1]]\n",
    "        eastPredictTeams[j], westPredictTeams[j] =\\\n",
    "            sepPredTeamsToEastAndWest(predictedTeams[j], eastTeamNames, westTeamNames)\n",
    "        \n",
    "        acc_i[j] = computeAccForPredict(eastPredictTeams[j]\\\n",
    "                                   , eastPlayoffTeams\\\n",
    "                                   , westPredictTeams[j]\\\n",
    "                                   , westPlayoffTeams)\n",
    "    \n",
    "        accLog[j].append(acc_i[j]*100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump(logReg[0], open(\"logregl1.p\", \"wb\"))\n",
    "cPickle.dump(logReg[1], open(\"logregl2.p\", \"wb\"))\n",
    "cPickle.dump(logReg[2], open(\"logreg.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainYears = []\n",
    "testYears = []\n",
    "\n",
    "for curr in play_years[1:]:\n",
    "    trainYears.append( str(2001) + '-' + str(2000 + curr) )\n",
    "    testYears.append( str(2000 + curr) + '-' + str(2001 + curr) )\n",
    "\n",
    "trainYears = np.transpose(np.array([trainYears]))\n",
    "testYears = np.transpose(np.array([testYears]))\n",
    "\n",
    "accl1 = np.transpose( np.array([accLog[0]]) )\n",
    "accl2 = np.transpose( np.array([accLog[1]]) )\n",
    "acc_ = np.transpose( np.array([accLog[2]]) )\n",
    "\n",
    "trainTimel1 = np.transpose( np.array([trainTime[0]]) )\n",
    "trainTimel2 = np.transpose( np.array([trainTime[1]]) )\n",
    "trainTimeUn = np.transpose( np.array([trainTime[2]]) )\n",
    "\n",
    "predTimel1 = np.transpose( np.array([predTime[0]]) )\n",
    "predTimel2 = np.transpose( np.array([predTime[1]]) )\n",
    "predTimeUn = np.transpose( np.array([predTime[2]]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# totAccTable = FF.create_table( pd.DataFrame( np.hstack((trainYears, testYears, accl1, accl2, acc_))\\\n",
    "#                                             , columns = ['Train Years', 'Test NBA Season'\\\n",
    "#                                                          , 'l1-Predict Acc.'\\\n",
    "#                                                          , 'l2-Predict Acc.'\\\n",
    "#                                                          , 'Un-normalized Predict Acc.']) )\n",
    "\n",
    "# totAccTable.layout.width = 1000\n",
    "# totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "# totAccTable.layout.update({'title': 'Accuracy of Progressively-Trained Model Over Each NBA Season'})\n",
    "# py.iplot(totAccTable, filename = 'progAccTable')\n",
    "\n",
    "accTable = pd.DataFrame( np.hstack((trainYears, testYears, accl1, accl2, acc_))\\\n",
    "                                            , columns = ['Train Years', 'Test Season'\\\n",
    "                                                         , '$\\ell_1$-Predict Acc., %'\\\n",
    "                                                         , '$\\ell_2$-Predict Acc., %'\\\n",
    "                                                         , 'Un-normalized Predict Acc., %'] )\n",
    "\n",
    "trainTable = pd.DataFrame( np.hstack((testYears, trainTimel1, trainTimel2, trainTimeUn))\\\n",
    "                        , columns = ['Test Season'\\\n",
    "                                    , '$\\ell_1$ (usec.)'\\\n",
    "                                    , '$\\ell_2$ (usec.)'\\\n",
    "                                    , '$un-norm.$ (usec.)'] )\n",
    "\n",
    "predTable = pd.DataFrame( np.hstack((testYears, predTimel1, predTimel2, predTimeUn))\\\n",
    "                        , columns = ['Test Season'\\\n",
    "                                    , '$\\ell_1$ (usec.)'\\\n",
    "                                    , '$\\ell_2$ (usec.)'\\\n",
    "                                    , '$un-norm.$ (usec.)'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Years</th>\n",
       "      <th>Test Season</th>\n",
       "      <th>$\\ell_1$-Predict Acc., %</th>\n",
       "      <th>$\\ell_2$-Predict Acc., %</th>\n",
       "      <th>Un-normalized Predict Acc., %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-2002</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>87.5</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-2003</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-2004</td>\n",
       "      <td>2004-2005</td>\n",
       "      <td>81.25</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-2005</td>\n",
       "      <td>2005-2006</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-2006</td>\n",
       "      <td>2006-2007</td>\n",
       "      <td>75.0</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001-2007</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-2008</td>\n",
       "      <td>2008-2009</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001-2009</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001-2010</td>\n",
       "      <td>2010-2011</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-2011</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001-2012</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2001-2013</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>75.0</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2001-2014</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>87.5</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2001-2015</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Years Test Season $\\ell_1$-Predict Acc., % $\\ell_2$-Predict Acc., %  \\\n",
       "0    2001-2002   2002-2003                     87.5                    81.25   \n",
       "1    2001-2003   2003-2004                     75.0                     75.0   \n",
       "2    2001-2004   2004-2005                    81.25                     75.0   \n",
       "3    2001-2005   2005-2006                    68.75                    68.75   \n",
       "4    2001-2006   2006-2007                     75.0                    81.25   \n",
       "5    2001-2007   2007-2008                     75.0                    68.75   \n",
       "6    2001-2008   2008-2009                     75.0                     75.0   \n",
       "7    2001-2009   2009-2010                    68.75                    68.75   \n",
       "8    2001-2010   2010-2011                     75.0                     75.0   \n",
       "9    2001-2011   2011-2012                    81.25                    81.25   \n",
       "10   2001-2012   2012-2013                    81.25                    81.25   \n",
       "11   2001-2013   2013-2014                     75.0                    81.25   \n",
       "12   2001-2014   2014-2015                     87.5                    81.25   \n",
       "13   2001-2015   2015-2016                     62.5                     62.5   \n",
       "\n",
       "   Un-normalized Predict Acc., %  \n",
       "0                          81.25  \n",
       "1                           75.0  \n",
       "2                           75.0  \n",
       "3                          68.75  \n",
       "4                          81.25  \n",
       "5                          68.75  \n",
       "6                           75.0  \n",
       "7                          68.75  \n",
       "8                           75.0  \n",
       "9                          81.25  \n",
       "10                         81.25  \n",
       "11                         81.25  \n",
       "12                         81.25  \n",
       "13                          62.5  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accTable.to_csv(\"logRegPredictAcc.csv\", encoding='utf-8', index = False)\n",
    "trainTable.to_csv(\"logRegTrainTime.csv\", encoding = 'utf-8', index = False)\n",
    "predTable.to_csv(\"logRegPredTime.csv\", encoding = 'utf-8', index = False)\n",
    "accTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(accLog)):\n",
    "    print(len(accLog[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process IV: C-Support Vector Classification\n",
    "### Focus I: Reformat Entire Dataset for Total Training\n",
    "\n",
    "After our analysis of the logistic regression classifier, we move forward to analyzing the accuracy of classifications using support vectore machines and c-support vector classification.\n",
    "\n",
    "First, we reformat the Entire Dataset for total model training across the dataset to analyze the best regularization strength, $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelazcona/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning:\n",
      "\n",
      "Data with input dtype object was converted to float64 by the scale function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag = False\n",
    "for year in play_years:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        teamNames = np.transpose( np.array( [teams[year]['team']] ) )\n",
    "        continue\n",
    "    teamNames = np.vstack( (teamNames, np.transpose( np.array( [teams[year]['team']] ) ) ) )\n",
    "X = np.hstack( ( teamNames, np.array(deepcopy(allTeamHist)) ) )\n",
    "X = pd.DataFrame(X, columns = [\"Team\"] + columns)\n",
    "\n",
    "del X['Team']\n",
    "del X['Playoff']\n",
    "del X['REB%']\n",
    "del X['PF']\n",
    "del X['TO']\n",
    "del X['OR']\n",
    "del X['FT%']\n",
    "del X['Conference']\n",
    "\n",
    "y = list( deepcopy(allTeamHist['Playoff']) )\n",
    "Xs = preprocessing.scale(np.array(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process IV: C-Support Vector Classification\n",
    "### Focus II: Intialize SVM Model Instance and Test Seperate Regularization Strengths on Entire Datatset Prediction\n",
    "Afterwards, we intialize an support vector machine model instance and test our classifier across several regularization strengths, $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.1\n",
      "1.0\n",
      "10.0\n",
      "100.0\n",
      "1000.0\n",
      "10000.0\n",
      "100000.0\n"
     ]
    }
   ],
   "source": [
    "Cvals = np.logspace(-2,5,8)\n",
    "\n",
    "acc = [[] for _ in range(4)]\n",
    "\n",
    "accMax = [0 for _ in range(4)]\n",
    "svmModels = [None for _ in range(4)]\n",
    "yHat = [None for _ in range(4)]\n",
    "C_max = [Cvals[0] for _ in range(4)]\n",
    "\n",
    "flag = False\n",
    "for C in Cvals:\n",
    "    \n",
    "    for i in range(4):\n",
    "        if i is 0:\n",
    "            k = 'linear'\n",
    "        elif i is 1:\n",
    "            k = 'rbf'\n",
    "        elif i is 2:\n",
    "            k = 'poly'\n",
    "        else:\n",
    "            k = 'sigmoid'\n",
    "        \n",
    "        svmModels[i] = svm.SVC(kernel = k, C = C)\n",
    "        \n",
    "        svmModels[i].fit(Xs, y)\n",
    "        yHat[i] = svmModels[i].predict(Xs)\n",
    "        acc[i].append( round(np.mean(yHat[i] == y)*100,2) )\n",
    "    \n",
    "    for i in range(4):\n",
    "        if accMax[i] < acc[i][-1]:\n",
    "            accMax[i] = acc[i][-1]\n",
    "            C_max[i] = C\n",
    "            \n",
    "    for i, a in enumerate(acc):\n",
    "        if i is 0:\n",
    "            k = 'linear'\n",
    "        elif i is 1:\n",
    "            k = 'rbf'\n",
    "        elif i is 2:\n",
    "            k = 'poly'\n",
    "        else:\n",
    "            k = 'sigmoid'\n",
    "    print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cvals = np.transpose( np.array([Cvals]) )\n",
    "acc_lin = np.transpose( np.array([acc[0]]) )\n",
    "acc_rbf = np.transpose( np.array([acc[1]]) )\n",
    "acc_poly = np.transpose( np.array([acc[2]]) )\n",
    "acc_sig = np.transpose( np.array([acc[3]]) )\n",
    "\n",
    "accTable = pd.DataFrame(np.hstack((Cvals, acc_lin, acc_rbf, acc_poly, acc_sig))\\\n",
    "                        ,columns = ['Reg. $C$', '$linear$ Acc.'\\\n",
    "                                    , '$rbf$ Acc.', '$poly$ Acc.'\\\n",
    "                                    , '$sigmoid$ Acc.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100000.0, 1000.0, 100000.0, 0.10000000000000001]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reg. $C$</th>\n",
       "      <th>$linear$ Acc.</th>\n",
       "      <th>$rbf$ Acc.</th>\n",
       "      <th>$poly$ Acc.</th>\n",
       "      <th>$sigmoid$ Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>71.81</td>\n",
       "      <td>53.69</td>\n",
       "      <td>57.27</td>\n",
       "      <td>63.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>73.83</td>\n",
       "      <td>72.71</td>\n",
       "      <td>66.22</td>\n",
       "      <td>70.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>73.38</td>\n",
       "      <td>77.63</td>\n",
       "      <td>76.96</td>\n",
       "      <td>65.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>73.60</td>\n",
       "      <td>86.35</td>\n",
       "      <td>80.31</td>\n",
       "      <td>66.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.00</td>\n",
       "      <td>73.60</td>\n",
       "      <td>95.08</td>\n",
       "      <td>87.70</td>\n",
       "      <td>66.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>73.38</td>\n",
       "      <td>100.00</td>\n",
       "      <td>91.05</td>\n",
       "      <td>66.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000.00</td>\n",
       "      <td>73.38</td>\n",
       "      <td>100.00</td>\n",
       "      <td>93.74</td>\n",
       "      <td>66.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100000.00</td>\n",
       "      <td>74.27</td>\n",
       "      <td>100.00</td>\n",
       "      <td>95.08</td>\n",
       "      <td>66.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Reg. $C$  $linear$ Acc.  $rbf$ Acc.  $poly$ Acc.  $sigmoid$ Acc.\n",
       "0       0.01          71.81       53.69        57.27           63.31\n",
       "1       0.10          73.83       72.71        66.22           70.92\n",
       "2       1.00          73.38       77.63        76.96           65.77\n",
       "3      10.00          73.60       86.35        80.31           66.00\n",
       "4     100.00          73.60       95.08        87.70           66.22\n",
       "5    1000.00          73.38      100.00        91.05           66.22\n",
       "6   10000.00          73.38      100.00        93.74           66.22\n",
       "7  100000.00          74.27      100.00        95.08           66.22"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accTable.to_csv('svmRegStrength.csv', encoding = 'utf-8')\n",
    "print(C_max)\n",
    "accTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process IV: C-Support Vector Classification\n",
    "### Focus IV: Use SVM's with Minimal Errors to Progressively Predict Throughout NBA Seasons\n",
    "Based on our tabulated results, we seee that using radial basis function and 3rd-degree polynomial kernels yield minimal errors when the regularization strength, $C$, is approximately equal to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100000.0, 1000.0, 100000.0, 0.10000000000000001]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileTrainData(teamsDict, year):\n",
    "    flag = False\n",
    "    for i in range(1,year+1):\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            Xtr = np.array(teamsDict[i])\n",
    "            continue\n",
    "        Xtr = np.vstack( (Xtr, np.array(teamsDict[i]) ) )\n",
    "    return Xtr\n",
    "    \n",
    "trainingFeatureSets = []\n",
    "trainingTargetSets = []\n",
    "for year in play_years[:-1]:\n",
    "    Xtr = compileTrainData(teamsDict, year)\n",
    "    ytr = deepcopy(Xtr[:,0])\n",
    "    Xtr = Xtr[:,1:]\n",
    "    \n",
    "    trainingFeatureSets.append(preprocessing.scale(Xtr))\n",
    "    trainingTargetSets.append(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accSVM = [[] for _ in range(4)]\n",
    "\n",
    "trainTime = [[] for _ in range(4)]\n",
    "predTime = [[] for _ in range(4)]\n",
    "\n",
    "acc_i = [None for _ in range(4)]\n",
    "svmModels = [None for _ in range(4)]\n",
    "yts_hat = [None for _ in range(4)]\n",
    "\n",
    "predictedTeams = [None for _ in range(4)]\n",
    "sortedPlayPred = [None for _ in range(4)]\n",
    "\n",
    "eastPredictTeams = [None for _ in range(4)]\n",
    "westPredictTeams = [None for _ in range(4)]\n",
    "\n",
    "for i, year in enumerate(play_years[1:]):\n",
    "    Xts = np.array(teamsDict[year])\n",
    "    yts = deepcopy(Xts[:,0])\n",
    "    Xts =  preprocessing.scale(Xts[:,1:])\n",
    "    \n",
    "    playOffIndices = np.where(np.array(yts) == True)\n",
    "    \n",
    "    westTeams = list(np.where(teams[year]['Conference'] == 'West')[0])\n",
    "    westTeamNames = list(np.array(teams[year]['team'])[westTeams])\n",
    "\n",
    "    temp = []\n",
    "    westPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for j in westPlayOffIndices:\n",
    "        if j in westTeams:\n",
    "            temp.append(j)\n",
    "    westPlayOffIndices = temp[:]\n",
    "    westPlayoffTeams = np.array(teams[year]['team'])[westPlayOffIndices]\n",
    "    \n",
    "    eastTeams = list(np.where(teams[year]['Conference'] == 'East')[0])\n",
    "    eastTeamNames = list(np.array(teams[year]['team'])[eastTeams])\n",
    "    \n",
    "    temp = []\n",
    "    eastPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for j in eastPlayOffIndices:\n",
    "        if j in eastTeams:\n",
    "            temp.append(j)\n",
    "    eastPlayOffIndices = temp[:]\n",
    "    eastPlayoffTeams = np.array(teams[year]['team'])[eastPlayOffIndices]\n",
    "    \n",
    "    for j in range(4):\n",
    "        if j is 0:\n",
    "            k = 'linear'\n",
    "        elif j is 1:\n",
    "            k = 'rbf'\n",
    "        elif j is 2:\n",
    "            k = 'poly'\n",
    "        else:\n",
    "            k = 'sigmoid'\n",
    "        \n",
    "        svmModels[j] = svm.SVC(kernel = k, C = C_max[j])\n",
    "        startTime = time()\n",
    "        svmModels[j].fit( trainingFeatureSets[i], trainingTargetSets[i] )\n",
    "        trainTime[j].append((time() - startTime)*1e3)\n",
    "        \n",
    "        startTime = time()\n",
    "        yts_hat[j] = svmModels[j].predict(Xts)\n",
    "        predTime[j].append((time() - startTime)*1e3)\n",
    "        \n",
    "        sortedPlayPred[j] = np.argsort(yts_hat[j][:])\n",
    "        predictedTeams[j] = np.array(teams[year]['team'])[sortedPlayPred[j][-1::-1]]\n",
    "        \n",
    "        eastPredictTeams[j], westPredictTeams[j] = sepPredTeamsToEastAndWest(predictedTeams[j], eastTeamNames, westTeamNames)\n",
    "        \n",
    "        acc_i[j] = computeAccForPredict(eastPredictTeams[j]\\\n",
    "                                   , eastPlayoffTeams\\\n",
    "                                   , westPredictTeams[j]\\\n",
    "                                   , westPlayoffTeams)\n",
    "        \n",
    "        accSVM[j].append( round(acc_i[j]*100,2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainYears = []\n",
    "testYears = []\n",
    "\n",
    "for curr in play_years[1:]:\n",
    "    trainYears.append( str(2001) + '-' + str(2000 + curr) )\n",
    "    testYears.append( str(2000 + curr) + '-' + str(2001 + curr) )\n",
    "\n",
    "trainYears = np.transpose(np.array([trainYears]))\n",
    "testYears = np.transpose(np.array([testYears]))\n",
    "\n",
    "SVMaccArr = []\n",
    "trainTimeArr = []\n",
    "predTimeArr = []\n",
    "\n",
    "for i in range(len(accSVM)):\n",
    "    SVMaccArr.append( np.transpose(np.array([accSVM[i]])) )\n",
    "    trainTimeArr.append( np.transpose(np.array([trainTime[i]])) )\n",
    "    predTimeArr.append( np.transpose(np.array([predTime[i]])) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# totAccTable = FF.create_table( pd.DataFrame( np.hstack((trainYears, testYears, acc_rbfArr, acc_polyArr))\\\n",
    "#                                             , columns = ['Train Years', 'Test NBA Season'\\\n",
    "#                                                          , 'rbf SVM Predict Acc.'\\\n",
    "#                                                          , 'poly SVM Predict Acc.']) )\n",
    "\n",
    "# totAccTable.layout.width = 700\n",
    "# totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "# totAccTable.layout.update({'title': 'Accuracy of Progressively-Trained SVM Model Over Each NBA Season'})\n",
    "# py.iplot(totAccTable, filename = 'progAccSVMTable')\n",
    "\n",
    "accTable = pd.DataFrame( np.hstack((trainYears, testYears, SVMaccArr[0], SVMaccArr[1], SVMaccArr[2], SVMaccArr[3]))\\\n",
    "                                            , columns = ['Train Years', 'Test NBA Season'\\\n",
    "                                                         , 'linear SVM Predict Acc.'\\\n",
    "                                                         , 'rbf SVM Predict Acc.'\\\n",
    "                                                         , 'poly SVM Predict Acc.'\\\n",
    "                                                         , 'sigmoid SVM Predict Acc.'])\n",
    "\n",
    "trainTable = pd.DataFrame( np.hstack((testYears, trainTimeArr[0], trainTimeArr[1], trainTimeArr[2], trainTimeArr[3]))\\\n",
    "                                            , columns = ['Test Season'\\\n",
    "                                                         , '$linear$ (msec.)'\\\n",
    "                                                         , '$rbf$ (msec.)'\\\n",
    "                                                         , '$poly$ (msec.)'\\\n",
    "                                                         , '$sigmoid$ (msec.)'])\n",
    "\n",
    "predTable = pd.DataFrame( np.hstack((testYears, predTimeArr[0], predTimeArr[1], predTimeArr[2], predTimeArr[3]))\\\n",
    "                                            , columns = ['Test Season'\\\n",
    "                                                         , '$linear$ (msec.)'\\\n",
    "                                                         , '$rbf$ (msec.)'\\\n",
    "                                                         , '$poly$ (msec.)'\\\n",
    "                                                         , '$sigmoid$ (msec.)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Years</th>\n",
       "      <th>Test NBA Season</th>\n",
       "      <th>linear SVM Predict Acc.</th>\n",
       "      <th>rbf SVM Predict Acc.</th>\n",
       "      <th>poly SVM Predict Acc.</th>\n",
       "      <th>sigmoid SVM Predict Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-2002</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>81.25</td>\n",
       "      <td>87.5</td>\n",
       "      <td>56.25</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-2003</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>81.25</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-2004</td>\n",
       "      <td>2004-2005</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-2005</td>\n",
       "      <td>2005-2006</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.75</td>\n",
       "      <td>62.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-2006</td>\n",
       "      <td>2006-2007</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001-2007</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>62.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-2008</td>\n",
       "      <td>2008-2009</td>\n",
       "      <td>68.75</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001-2009</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>81.25</td>\n",
       "      <td>62.5</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001-2010</td>\n",
       "      <td>2010-2011</td>\n",
       "      <td>62.5</td>\n",
       "      <td>56.25</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-2011</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>56.25</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001-2012</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>68.75</td>\n",
       "      <td>62.5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2001-2013</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>68.75</td>\n",
       "      <td>50.0</td>\n",
       "      <td>43.75</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2001-2014</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>68.75</td>\n",
       "      <td>81.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2001-2015</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>62.5</td>\n",
       "      <td>56.25</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Years Test NBA Season linear SVM Predict Acc. rbf SVM Predict Acc.  \\\n",
       "0    2001-2002       2002-2003                   81.25                 87.5   \n",
       "1    2001-2003       2003-2004                   81.25                 75.0   \n",
       "2    2001-2004       2004-2005                    75.0                 62.5   \n",
       "3    2001-2005       2005-2006                    75.0                68.75   \n",
       "4    2001-2006       2006-2007                    75.0                 62.5   \n",
       "5    2001-2007       2007-2008                    62.5                 75.0   \n",
       "6    2001-2008       2008-2009                   68.75                 62.5   \n",
       "7    2001-2009       2009-2010                   81.25                 62.5   \n",
       "8    2001-2010       2010-2011                    62.5                56.25   \n",
       "9    2001-2011       2011-2012                    75.0                 75.0   \n",
       "10   2001-2012       2012-2013                   68.75                 62.5   \n",
       "11   2001-2013       2013-2014                   68.75                 50.0   \n",
       "12   2001-2014       2014-2015                    75.0                 62.5   \n",
       "13   2001-2015       2015-2016                    62.5                56.25   \n",
       "\n",
       "   poly SVM Predict Acc. sigmoid SVM Predict Acc.  \n",
       "0                  56.25                     62.5  \n",
       "1                   75.0                     62.5  \n",
       "2                   75.0                    68.75  \n",
       "3                   62.5                     75.0  \n",
       "4                   62.5                     75.0  \n",
       "5                   62.5                     75.0  \n",
       "6                   62.5                     75.0  \n",
       "7                  68.75                    68.75  \n",
       "8                   50.0                     75.0  \n",
       "9                  56.25                    81.25  \n",
       "10                  62.5                     75.0  \n",
       "11                 43.75                    68.75  \n",
       "12                 68.75                    81.25  \n",
       "13                  50.0                     75.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accTable.to_csv('svmPredictAccuracy.csv', encoding = 'utf-8', index = False)\n",
    "trainTable.to_csv('svmTrainTable.csv', encoding = 'utf-8', index = False)\n",
    "predTable.to_csv('svmPredTable.csv', encoding = 'utf-8', index = False)\n",
    "\n",
    "accTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(accSVM)):\n",
    "    print(len(accSVM[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process V: Random Forest Classification\n",
    "### Focus I: Reformat Entire Dataset for Total Training\n",
    "After our analysis of the support vector machine (SVM) classifier, we move forward to analyzing the accuracy of classifications using random forests or random decision forests for classification.\n",
    "\n",
    "Random forests operate by constructing a multitude of decision tress at training time and outputting the class that is the mode of the classes. Rnadom decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "\n",
    "First, we reformat the Entire Dataset for total model training across the dataset to analyze the best regularization strength, $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelazcona/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning:\n",
      "\n",
      "Data with input dtype object was converted to float64 by the scale function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag = False\n",
    "for year in play_years:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        teamNames = np.transpose( np.array( [teams[year]['team']] ) )\n",
    "        continue\n",
    "    teamNames = np.vstack( (teamNames, np.transpose( np.array( [teams[year]['team']] ) ) ) )\n",
    "X = np.hstack( ( teamNames, np.array(deepcopy(allTeamHist)) ) )\n",
    "X = pd.DataFrame(X, columns = [\"Team\"] + columns)\n",
    "\n",
    "del X['Team']\n",
    "del X['Playoff']\n",
    "del X['REB%']\n",
    "del X['PF']\n",
    "del X['TO']\n",
    "del X['OR']\n",
    "del X['FT%']\n",
    "del X['Conference']\n",
    "\n",
    "y = list( deepcopy(allTeamHist['Playoff']) )\n",
    "Xs = preprocessing.scale(np.array(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process V: Random Forest Classification\n",
    "### Focus II: Intialize Random Forest Model Instance and Test Seperate Tree Counts on Entire Datatset Prediction\n",
    "Afterwards, we intialize a random forest model instance and test our classifier across several numbers of trees to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_est_vals = np.logspace(1,3,20)\n",
    "num_est_vals = num_est_vals.ravel().tolist()\n",
    "for i in range(len(num_est_vals)):\n",
    "    num_est_vals[i] = int(num_est_vals[i])\n",
    "\n",
    "acc = []\n",
    "\n",
    "acc_min = 0\n",
    "\n",
    "flag = False\n",
    "for num_est in num_est_vals:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        est_min = num_est\n",
    "        \n",
    "    rfModel = RandomForestClassifier(n_estimators = num_est)\n",
    "    \n",
    "    rfModel.fit(Xs,y)\n",
    "    \n",
    "    y_hat = rfModel.predict(Xs)\n",
    "    \n",
    "    acc_i = round( np.mean(y_hat == y)*100, 2)\n",
    "    \n",
    "    acc.append(acc_i)\n",
    "    \n",
    "    if (acc_min < acc_i):\n",
    "        acc_min = acc_i\n",
    "        est_min = num_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process V: Random Forest Classification\n",
    "### Focus III: Tabulate & Analyze Entire Dataset Training Errors\n",
    "\n",
    "Next, we tabulate our results and analyze the errors based on the tree numbers on each of our Random Forest classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_est_valsArr = np.transpose( np.array([num_est_vals]))\n",
    "\n",
    "RFaccArr = np.transpose( np.array([acc]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Estimators (Trees)</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>99.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>99.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>99.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>99.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>99.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>69.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>88.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>112.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>143.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>183.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>233.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>297.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>379.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>483.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>615.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>784.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Estimators (Trees)  Accuracy (%)\n",
       "0                           10.0         99.33\n",
       "1                           12.0         99.55\n",
       "2                           16.0         99.78\n",
       "3                           20.0         99.78\n",
       "4                           26.0         99.55\n",
       "5                           33.0        100.00\n",
       "6                           42.0        100.00\n",
       "7                           54.0        100.00\n",
       "8                           69.0        100.00\n",
       "9                           88.0        100.00\n",
       "10                         112.0        100.00\n",
       "11                         143.0        100.00\n",
       "12                         183.0        100.00\n",
       "13                         233.0        100.00\n",
       "14                         297.0        100.00\n",
       "15                         379.0        100.00\n",
       "16                         483.0        100.00\n",
       "17                         615.0        100.00\n",
       "18                         784.0        100.00\n",
       "19                        1000.0        100.00"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# totAccTable = FF.create_table( pd.DataFrame( np.hstack((num_est_valsArr, accArr))\\\n",
    "#                                                    , columns = ['Number of Estimators (Trees)', 'Accuracy (%)']) )\n",
    "\n",
    "# totAccTable.layout.width = 500\n",
    "# totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "# totAccTable.layout.update({'title': 'Random Forest Classifier Error Rates'})\n",
    "# py.iplot(totAccTable, filename = 'overRandomForestTable')\n",
    "\n",
    "accTable = pd.DataFrame( np.hstack((num_est_valsArr, RFaccArr))\\\n",
    "                                                   , columns = ['Number of Estimators (Trees)', 'Accuracy (%)'])\n",
    "\n",
    "accTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accTable.to_csv(\"rfTreeAcc.csv\", encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_max = est_min\n",
    "n_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process V: Random Forest Classification\n",
    "### Focus IV: Use Random Forest Models with Minimal Errors to Progressively Predict Throughout NBA Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileTrainData(teamsDict, year):\n",
    "    flag = False\n",
    "    for i in range(1,year+1):\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            Xtr = np.array(teamsDict[i])\n",
    "            continue\n",
    "        Xtr = np.vstack( (Xtr, np.array(teamsDict[i]) ) )\n",
    "    return Xtr\n",
    "    \n",
    "trainingFeatureSets = []\n",
    "trainingTargetSets = []\n",
    "for year in play_years[:-1]:\n",
    "    Xtr = compileTrainData(teamsDict, year)\n",
    "    ytr = deepcopy(Xtr[:,0])\n",
    "    Xtr = Xtr[:,1:]\n",
    "    \n",
    "    trainingFeatureSets.append(preprocessing.scale(Xtr))\n",
    "    trainingTargetSets.append(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accRF = []\n",
    "trainTime = []\n",
    "predTime = []\n",
    "\n",
    "for i, year in enumerate(play_years[1:]):\n",
    "    Xts = np.array(teamsDict[year])\n",
    "    yts = deepcopy(Xts[:,0])\n",
    "    Xts =  preprocessing.scale(Xts[:,1:])\n",
    "    \n",
    "    rfModel = RandomForestClassifier(est_min)\n",
    "    \n",
    "    startTime = time()\n",
    "    rfModel.fit( trainingFeatureSets[i], trainingTargetSets[i] )\n",
    "    trainTime.append( round( (time() - startTime)*1e3, 2 ) )\n",
    "    \n",
    "    startTime = time()\n",
    "    yts_hat = rfModel.predict_proba(Xts)\n",
    "    predTime.append( round( (time() - startTime)*1e3, 2 ) )\n",
    "    \n",
    "    playOffIndices = np.where(np.array(yts) == True)\n",
    "    \n",
    "    westTeams = list(np.where(teams[year]['Conference'] == 'West')[0])\n",
    "    westTeamNames = list(np.array(teams[year]['team'])[westTeams])\n",
    "\n",
    "    temp = []\n",
    "    westPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for j in westPlayOffIndices:\n",
    "        if j in westTeams:\n",
    "            temp.append(j)\n",
    "    westPlayOffIndices = temp[:]\n",
    "    westPlayoffTeams = np.array(teams[year]['team'])[westPlayOffIndices]\n",
    "    \n",
    "    eastTeams = list(np.where(teams[year]['Conference'] == 'East')[0])\n",
    "    eastTeamNames = list(np.array(teams[year]['team'])[eastTeams])\n",
    "    \n",
    "    temp = []\n",
    "    eastPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for j in eastPlayOffIndices:\n",
    "        if j in eastTeams:\n",
    "            temp.append(j)\n",
    "    eastPlayOffIndices = temp[:]\n",
    "    eastPlayoffTeams = np.array(teams[year]['team'])[eastPlayOffIndices]\n",
    "    \n",
    "    sortedPlayPred = np.argsort(yts_hat[:,1])\n",
    "    predictedTeams = np.array(teams[year]['team'])[sortedPlayPred[-1::-1]]\n",
    "    eastPredictTeams, westPredictTeams =\\\n",
    "    sepPredTeamsToEastAndWest(predictedTeams, eastTeamNames, westTeamNames)\n",
    "    \n",
    "    acc_i = computeAccForPredict(eastPredictTeams\\\n",
    "                                   , eastPlayoffTeams\\\n",
    "                                   , westPredictTeams\\\n",
    "                                   , westPlayoffTeams)\n",
    "    \n",
    "    accRF.append(round( acc_i*100, 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump(rfModel, open(\"rfModel.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainYears = []\n",
    "testYears = []\n",
    "\n",
    "for curr in play_years[1:]:\n",
    "    trainYears.append( str(2001) + '-' + str(2000 + curr) )\n",
    "    testYears.append( str(2000 + curr) + '-' + str(2001 + curr) )\n",
    "\n",
    "trainYears = np.transpose(np.array([trainYears]))\n",
    "testYears = np.transpose(np.array([testYears]))\n",
    "\n",
    "acc_RFArr = np.transpose( np.array([accRF]) )\n",
    "trainTime = np.transpose( np.array([trainTime]) )\n",
    "predTime = np.transpose( np.array([predTime]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Years</th>\n",
       "      <th>Test Season</th>\n",
       "      <th>RF Acc. %</th>\n",
       "      <th>Train. Time (msec.)</th>\n",
       "      <th>Predict. Time (msec.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-2002</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>81.25</td>\n",
       "      <td>84.27</td>\n",
       "      <td>12.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-2003</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>75.0</td>\n",
       "      <td>58.29</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-2004</td>\n",
       "      <td>2004-2005</td>\n",
       "      <td>75.0</td>\n",
       "      <td>36.83</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-2005</td>\n",
       "      <td>2005-2006</td>\n",
       "      <td>68.75</td>\n",
       "      <td>33.54</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-2006</td>\n",
       "      <td>2006-2007</td>\n",
       "      <td>68.75</td>\n",
       "      <td>36.68</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001-2007</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>75.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-2008</td>\n",
       "      <td>2008-2009</td>\n",
       "      <td>75.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001-2009</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>68.75</td>\n",
       "      <td>46.8</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001-2010</td>\n",
       "      <td>2010-2011</td>\n",
       "      <td>81.25</td>\n",
       "      <td>39.76</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-2011</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>81.25</td>\n",
       "      <td>43.77</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001-2012</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>81.25</td>\n",
       "      <td>44.3</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2001-2013</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>68.75</td>\n",
       "      <td>63.45</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2001-2014</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.16</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2001-2015</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.86</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Years Test Season RF Acc. % Train. Time (msec.) Predict. Time (msec.)\n",
       "0    2001-2002   2002-2003     81.25               84.27                 12.87\n",
       "1    2001-2003   2003-2004      75.0               58.29                   2.2\n",
       "2    2001-2004   2004-2005      75.0               36.83                   2.3\n",
       "3    2001-2005   2005-2006     68.75               33.54                  2.39\n",
       "4    2001-2006   2006-2007     68.75               36.68                  2.14\n",
       "5    2001-2007   2007-2008      75.0               38.49                  2.16\n",
       "6    2001-2008   2008-2009      75.0                44.5                  2.63\n",
       "7    2001-2009   2009-2010     68.75                46.8                  2.39\n",
       "8    2001-2010   2010-2011     81.25               39.76                  2.16\n",
       "9    2001-2011   2011-2012     81.25               43.77                  2.47\n",
       "10   2001-2012   2012-2013     81.25                44.3                  2.41\n",
       "11   2001-2013   2013-2014     68.75               63.45                  3.85\n",
       "12   2001-2014   2014-2015      75.0               79.16                  3.95\n",
       "13   2001-2015   2015-2016      75.0               76.86                  4.11"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# totAccTable = FF.create_table( pd.DataFrame( np.hstack((trainYears, testYears, acc_RFArr))\\\n",
    "#                                             , columns = ['Train Years', 'Test NBA Season'\\\n",
    "#                                                          , 'Random Forest Accuracy']) )\n",
    "\n",
    "# totAccTable.layout.width = 750\n",
    "# totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "# totAccTable.layout.update({'title': 'Accuracy of Progressively-Trained Random Forest Model Over Each NBA Season'})\n",
    "# py.iplot(totAccTable, filename = 'progAccRandomForestTable')\n",
    "\n",
    "accTable = pd.DataFrame( np.hstack((trainYears, testYears, acc_RFArr, trainTime, predTime))\\\n",
    "                                            , columns = ['Train Years', 'Test Season'\\\n",
    "                                                         , 'RF Acc. %'\\\n",
    "                                                         , 'Train. Time (msec.)'\\\n",
    "                                                         , 'Predict. Time (msec.)'])\n",
    "\n",
    "accTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accTable.to_csv(\"RFpredictAccuracy.csv\", encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(accRF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process VI: Decision Tree Classification\n",
    "### Focus: Intialize Decision Tree Model Instance and Predict Outcomes\n",
    "Afterwards, we intialize a decision tree model instance and test our classifier across several NBA seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileTrainData(teamsDict, year):\n",
    "    flag = False\n",
    "    for i in range(1,year+1):\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            Xtr = np.array(teamsDict[i])\n",
    "            continue\n",
    "        Xtr = np.vstack( (Xtr, np.array(teamsDict[i]) ) )\n",
    "    return Xtr\n",
    "    \n",
    "trainingFeatureSets = []\n",
    "trainingTargetSets = []\n",
    "for year in play_years[:-1]:\n",
    "    Xtr = compileTrainData(teamsDict, year)\n",
    "    ytr = deepcopy(Xtr[:,0])\n",
    "    Xtr = Xtr[:,1:]\n",
    "    \n",
    "    trainingFeatureSets.append(preprocessing.scale(Xtr))\n",
    "    trainingTargetSets.append(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accTree = []\n",
    "trainTime = []\n",
    "predTime = []\n",
    "for i, year in enumerate(play_years[1:]):\n",
    "    Xts = np.array(teamsDict[year])\n",
    "    yts = deepcopy(Xts[:,0])\n",
    "    Xts =  preprocessing.scale(Xts[:,1:])\n",
    "    \n",
    "    treeModel = DecisionTreeClassifier()\n",
    "    \n",
    "    startTime = time()\n",
    "    treeModel.fit( trainingFeatureSets[i], trainingTargetSets[i] )\n",
    "    trainTime.append( round( (time() - startTime)*1e3, 2) )\n",
    "    \n",
    "    startTime = time()\n",
    "    yts_hat = treeModel.predict_proba(Xts)\n",
    "    predTime.append( round( (time() - startTime)*1e3, 2) )\n",
    "    \n",
    "    playOffIndices = np.where(np.array(yts) == True)\n",
    "    \n",
    "    westTeams = list(np.where(teams[year]['Conference'] == 'West')[0])\n",
    "    westTeamNames = list(np.array(teams[year]['team'])[westTeams])\n",
    "\n",
    "    temp = []\n",
    "    westPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for j in westPlayOffIndices:\n",
    "        if j in westTeams:\n",
    "            temp.append(j)\n",
    "    westPlayOffIndices = temp[:]\n",
    "    westPlayoffTeams = np.array(teams[year]['team'])[westPlayOffIndices]\n",
    "    \n",
    "    eastTeams = list(np.where(teams[year]['Conference'] == 'East')[0])\n",
    "    eastTeamNames = list(np.array(teams[year]['team'])[eastTeams])\n",
    "    \n",
    "    temp = []\n",
    "    eastPlayOffIndices = list(playOffIndices[:][0])\n",
    "    for j in eastPlayOffIndices:\n",
    "        if j in eastTeams:\n",
    "            temp.append(j)\n",
    "    eastPlayOffIndices = temp[:]\n",
    "    eastPlayoffTeams = np.array(teams[year]['team'])[eastPlayOffIndices]\n",
    "    \n",
    "    sortedPlayPred = np.argsort(yts_hat[:,1])\n",
    "    predictedTeams = np.array(teams[year]['team'])[sortedPlayPred[-1::-1]]\n",
    "    eastPredictTeams, westPredictTeams =\\\n",
    "    sepPredTeamsToEastAndWest(predictedTeams, eastTeamNames, westTeamNames)\n",
    "    \n",
    "    acc_i = computeAccForPredict(eastPredictTeams\\\n",
    "                                   , eastPlayoffTeams\\\n",
    "                                   , westPredictTeams\\\n",
    "                                   , westPlayoffTeams)\n",
    "    \n",
    "    accTree.append(round(acc_i*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump(treeModel, open(\"treeModel.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainYears = []\n",
    "testYears = []\n",
    "\n",
    "for curr in play_years[1:]:\n",
    "    trainYears.append( str(2001) + '-' + str(2000 + curr) )\n",
    "    testYears.append( str(2000 + curr) + '-' + str(2001 + curr) )\n",
    "\n",
    "trainYears = np.transpose(np.array([trainYears]))\n",
    "testYears = np.transpose(np.array([testYears]))\n",
    "\n",
    "acc_TreeArr = np.transpose( np.array([accTree]) )\n",
    "trainTime = np.transpose( np.array([trainTime]) )\n",
    "predTime = np.transpose( np.array([predTime]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Years</th>\n",
       "      <th>Test Season</th>\n",
       "      <th>DT Acc., %</th>\n",
       "      <th>Train Time (msec.)</th>\n",
       "      <th>Predict Time (msec.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-2002</td>\n",
       "      <td>2002-2003</td>\n",
       "      <td>81.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-2003</td>\n",
       "      <td>2003-2004</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-2004</td>\n",
       "      <td>2004-2005</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-2005</td>\n",
       "      <td>2005-2006</td>\n",
       "      <td>62.5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-2006</td>\n",
       "      <td>2006-2007</td>\n",
       "      <td>68.75</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001-2007</td>\n",
       "      <td>2007-2008</td>\n",
       "      <td>68.75</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2001-2008</td>\n",
       "      <td>2008-2009</td>\n",
       "      <td>68.75</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001-2009</td>\n",
       "      <td>2009-2010</td>\n",
       "      <td>68.75</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2001-2010</td>\n",
       "      <td>2010-2011</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2001-2011</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>68.75</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001-2012</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>68.75</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2001-2013</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>68.75</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2001-2014</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>62.5</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2001-2015</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>68.75</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Years Test Season DT Acc., % Train Time (msec.) Predict Time (msec.)\n",
       "0    2001-2002   2002-2003      81.25                0.5                 0.15\n",
       "1    2001-2003   2003-2004       75.0               0.74                 0.16\n",
       "2    2001-2004   2004-2005       75.0               0.91                 0.18\n",
       "3    2001-2005   2005-2006       62.5               0.95                 0.16\n",
       "4    2001-2006   2006-2007      68.75               1.41                 0.22\n",
       "5    2001-2007   2007-2008      68.75                1.6                 0.18\n",
       "6    2001-2008   2008-2009      68.75               1.81                 0.16\n",
       "7    2001-2009   2009-2010      68.75               2.06                  0.2\n",
       "8    2001-2010   2010-2011       75.0               2.39                 0.22\n",
       "9    2001-2011   2011-2012      68.75               2.57                 0.13\n",
       "10   2001-2012   2012-2013      68.75               2.19                 0.18\n",
       "11   2001-2013   2013-2014      68.75               3.18                 0.19\n",
       "12   2001-2014   2014-2015       62.5               3.56                 0.19\n",
       "13   2001-2015   2015-2016      68.75               3.82                 0.19"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# totAccTable = FF.create_table( pd.DataFrame( np.hstack((trainYears, testYears, acc_TreeArr))\\\n",
    "#                                             , columns = ['Train Years', 'Test NBA Season'\\\n",
    "#                                                          , 'Decision Tree Accuracy']) )\n",
    "\n",
    "# totAccTable.layout.width = 750\n",
    "# totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "# totAccTable.layout.update({'title': 'Accuracy of Progressively-Trained Decision Tree Model Over Each NBA Season'})\n",
    "# py.iplot(totAccTable, filename = 'progAccDecisionTreeTable')\n",
    "\n",
    "accTable = pd.DataFrame( np.hstack((trainYears, testYears, acc_TreeArr, trainTime, predTime))\\\n",
    "                                            , columns = ['Train Years', 'Test Season'\\\n",
    "                                                         , 'DT Acc., %'\\\n",
    "                                                         , 'Train Time (msec.)'\\\n",
    "                                                         , 'Predict Time (msec.)'])\n",
    "\n",
    "accTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Train Years', 'Test Season', 'DT Acc., %', 'Train Time (msec.)',\n",
       "       'Predict Time (msec.)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accTable.to_csv(\"decTreePredictAccuracy.csv\", encoding = 'utf-8', index = False)\n",
    "accTable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(accTree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion for NBA-Playoff Predictions\n",
    "\n",
    "Based on our results for the earlier seasons in the NBA, it makes sense to use the logistic regression classifiers for predicting NBA-Playoff contention, however we see that as we obtain more training data and try to predict some of the more recent NBA-Playoff contenders, the random forest classifier model's accuracy begins to level with that of the logistic regression classifiers. Therefore, we hypothesize that as we continue to obtain more data for the coming NBA seasons, the random forest classifier and logistic classifiers will continue to be the most accurate of the classifier models that we analyze in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalAcc = [accLog[0], accLog[1], accLog[2], accSVM[0], accSVM[1], accSVM[2], accSVM[3], accRF, accTree]\n",
    "names = ['l1-penalized logistic', 'l2-penalized logistic',\n",
    "         'unregularized logistic', 'linear SVM',\n",
    "         'radial basis SVM', ' polynomial SVM', \n",
    "         'sigmoid SVM', 'random forest', 'decision tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "predictYears = []\n",
    "for i in play_years[1:]:\n",
    "    predictYears.append( str(2000+i) + '-' + str(2000+i+1) )\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    print(len(currAcc))\n",
    "    trace = go.Bar(\n",
    "                x = currAcc,\n",
    "                y = predictYears,\n",
    "                orientation = 'h',\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/34.embed\" height=\"1000px\" width=\"1000px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "            title = 'Progressive Classifier Model Accuracies Throughout NBA Seasons',\n",
    "            autosize = True,\n",
    "            width = 1000,\n",
    "            height = 1000)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'All Model Acccuracies Throughout NBA Seasons')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/40.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[0],\n",
    "                x = predictYears[0],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2002, Predict: 2002-2003)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2002, Predict: 2002-2003)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/42.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[1],\n",
    "                x = predictYears[1],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2003, Predict: 2003-2004)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2003, Predict: 2003-2004)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/44.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[2],\n",
    "                x = predictYears[2],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2004, Predict: 2004-2005)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2004, Predict: 2004-2005)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/46.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[3],\n",
    "                x = predictYears[3],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2005, Predict: 2005-2006)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2005, Predict: 2005-2006)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/48.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[4],\n",
    "                x = predictYears[4],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2006, Predict: 2006-2007)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2006, Predict: 2006-2007)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/50.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[5],\n",
    "                x = predictYears[5],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2007, Predict: 2007-2008)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2007, Predict: 2007-2008)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/52.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[6],\n",
    "                x = predictYears[6],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2008, Predict: 2008-2009)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2008, Predict: 2008-2009)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/54.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[7],\n",
    "                x = predictYears[7],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2009, Predict: 2009-2010)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2009, Predict: 2009-2010)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/56.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[8],\n",
    "                x = predictYears[8],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2010, Predict: 2010-2011)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2010, Predict: 2010-2011)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.25\n",
      "81.25\n",
      "81.25\n",
      "75.0\n",
      "75.0\n",
      "56.25\n",
      "81.25\n",
      "81.25\n",
      "68.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/58.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    print(currAcc[9])\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[9],\n",
    "                x = predictYears[9],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2011, Predict: 2011-2012)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2011, Predict: 2011-2012)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/60.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[10],\n",
    "                x = predictYears[10],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2012, Predict: 2012-2013)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2012, Predict: 2012-2013)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.25\n",
      "81.25\n",
      "81.25\n",
      "75.0\n",
      "75.0\n",
      "56.25\n",
      "81.25\n",
      "81.25\n",
      "68.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/62.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    print(currAcc[9])\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[11],\n",
    "                x = predictYears[11],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2013, Predict: 2013-2014)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2013, Predict: 2013-2014)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.25\n",
      "81.25\n",
      "81.25\n",
      "75.0\n",
      "75.0\n",
      "56.25\n",
      "81.25\n",
      "81.25\n",
      "68.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/64.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    print(currAcc[9])\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[12],\n",
    "                x = predictYears[12],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2014, Predict: 2014-2015)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2014, Predict: 2014-2015)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.25\n",
      "81.25\n",
      "81.25\n",
      "75.0\n",
      "75.0\n",
      "56.25\n",
      "81.25\n",
      "81.25\n",
      "68.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona2022/66.embed\" height=\"900px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    print(currAcc[9])\n",
    "    trace = go.Bar(\n",
    "                y = currAcc[13],\n",
    "                x = predictYears[13],\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "layout = go.Layout(\n",
    "            title = 'Classifier Model Accuracies (Train: 2001-2015, Predict: 2015-2016)',\n",
    "            autosize = True,\n",
    "            width = 700,\n",
    "            height = 900)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'Classifier Model Accuracies (Train: 2001-2015, Predict: 2015-2016)')\n",
    "allAccPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1-penalized logistic\n",
      "unregularized logistic\n",
      "l2-penalized logistic\n",
      "random forest\n",
      "sigmoid SVM\n",
      "linear SVM\n",
      "decision tree\n",
      "radial basis SVM\n",
      " polynomial SVM\n",
      "\n",
      "random forest\n",
      "decision tree\n",
      "sigmoid SVM\n",
      "l2-penalized logistic\n",
      "unregularized logistic\n",
      "linear SVM\n",
      "l1-penalized logistic\n",
      " polynomial SVM\n",
      "radial basis SVM\n"
     ]
    }
   ],
   "source": [
    "accMeans = []\n",
    "accVar = []\n",
    "for i in totalAcc:\n",
    "    accMeans.append(np.mean(i))\n",
    "    accVar.append(np.var(i))\n",
    "    \n",
    "accMeans = np.argsort(accMeans)[-1::-1]\n",
    "accVar = np.argsort(accVar)\n",
    "\n",
    "accMeans = accMeans.ravel().tolist()\n",
    "\n",
    "for i in accMeans:\n",
    "    print(names[i])\n",
    "print()\n",
    "for i in accVar:\n",
    "    print(names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.50</td>\n",
       "      <td>75.00</td>\n",
       "      <td>81.25</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>87.50</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>81.25</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>81.25</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>62.50</td>\n",
       "      <td>68.75</td>\n",
       "      <td>81.25</td>\n",
       "      <td>62.50</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.50</td>\n",
       "      <td>75.00</td>\n",
       "      <td>62.50</td>\n",
       "      <td>68.75</td>\n",
       "      <td>62.50</td>\n",
       "      <td>75.00</td>\n",
       "      <td>62.50</td>\n",
       "      <td>62.50</td>\n",
       "      <td>56.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>62.50</td>\n",
       "      <td>50.00</td>\n",
       "      <td>62.50</td>\n",
       "      <td>56.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>62.50</td>\n",
       "      <td>62.50</td>\n",
       "      <td>62.50</td>\n",
       "      <td>62.50</td>\n",
       "      <td>68.75</td>\n",
       "      <td>50.00</td>\n",
       "      <td>56.25</td>\n",
       "      <td>62.50</td>\n",
       "      <td>43.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62.50</td>\n",
       "      <td>62.50</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>81.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>81.25</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>81.25</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81.25</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>62.50</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>75.00</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>62.50</td>\n",
       "      <td>68.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9   \\\n",
       "0  87.50  75.00  81.25  68.75  75.00  75.00  75.00  68.75  75.00  81.25   \n",
       "1  81.25  75.00  75.00  68.75  81.25  68.75  75.00  68.75  75.00  81.25   \n",
       "2  81.25  75.00  75.00  68.75  81.25  68.75  75.00  68.75  75.00  81.25   \n",
       "3  81.25  81.25  75.00  75.00  75.00  62.50  68.75  81.25  62.50  75.00   \n",
       "4  87.50  75.00  62.50  68.75  62.50  75.00  62.50  62.50  56.25  75.00   \n",
       "5  56.25  75.00  75.00  62.50  62.50  62.50  62.50  68.75  50.00  56.25   \n",
       "6  62.50  62.50  68.75  75.00  75.00  75.00  75.00  68.75  75.00  81.25   \n",
       "7  81.25  75.00  75.00  68.75  68.75  75.00  75.00  68.75  81.25  81.25   \n",
       "8  81.25  75.00  75.00  62.50  68.75  68.75  68.75  68.75  75.00  68.75   \n",
       "\n",
       "      10     11     12     13  \n",
       "0  81.25  75.00  87.50  62.50  \n",
       "1  81.25  81.25  81.25  62.50  \n",
       "2  81.25  81.25  81.25  62.50  \n",
       "3  68.75  68.75  75.00  62.50  \n",
       "4  62.50  50.00  62.50  56.25  \n",
       "5  62.50  43.75  68.75  50.00  \n",
       "6  75.00  68.75  81.25  75.00  \n",
       "7  81.25  68.75  75.00  75.00  \n",
       "8  68.75  68.75  62.50  68.75  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTable = pd.DataFrame(totalAcc)\n",
    "dataTable.head(len(dataTable))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
