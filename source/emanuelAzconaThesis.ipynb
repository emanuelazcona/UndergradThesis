{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting NBA Success Using Machine Learning\n",
    "## Created by: Emanuel Azcona\n",
    "## Course: Introduction to Machine Learning & Senior Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries for handling dataframes, arrays, and generating the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gen_data import gen_data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF\n",
    "py.sign_in(username='emanuelazcona', api_key='Xzr6euzNyeujz9dBqG2M')\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from statsmodels.stats.weightstats import ztest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cumulative Player Databases\n",
    "\n",
    "First, we use our user-created function to develop two seperate dictionaries:\n",
    "\n",
    "- A dictionary of players by NBA Season\n",
    "- A dictionary of teams by NBA Season\n",
    "\n",
    "Each dictionary entry (in both dictionaries) is a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first year of NBA seasons we'd like to store\n",
    "start = 1\n",
    "# end year ....\n",
    "end = 16\n",
    "\n",
    "# returns two dictionaries:\n",
    "# 1. player dictionary where all NBA players are available in a dataframe, \n",
    "#       each dict. key is the NBA season's start year, ex: 2001 = 1, 2003 = 3\n",
    "# 2. team dictionary .....\n",
    "players, teams = gen_data(start,end)\n",
    "\n",
    "# store all the NBA years we used in a list\n",
    "play_years = list( players.keys() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dictionary of NBA Seasons with NBA teams\n",
    "\n",
    "Next, we create a dictionary of NBA seasons with each key referencing a dictionary of NBA teams for that respective season. Each entry of the teams dictionary has a dataframe of players on that team, in that year essentially.\n",
    "\n",
    "- NBA Season\n",
    "    - Team\n",
    "        - Players\n",
    "        \n",
    "Example:\n",
    "\n",
    "- '15-16'\n",
    "    - Oklahoma City Thunder (okl)\n",
    "        - Total Team Stats.\n",
    "        - Players & Player Stats.\n",
    "            - durant,kevin\n",
    "                - GP\n",
    "                - FGM\n",
    "                - etc..\n",
    "            - westbrook,russell\n",
    "                - GP\n",
    "                - FGM\n",
    "                - etc..\n",
    "            - etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create basketball team class which stores players for team and total team statistics\n",
    "class basketBallTeam:\n",
    "    def __init__(self, players):\n",
    "        self.players = players\n",
    "        totalStats = []\n",
    "\n",
    "# function for computing the overall team statistics of a team\n",
    "def computeTeamStats(currTeam, i):\n",
    "    FGM = np.sum(currTeam[:,5])\n",
    "    FGA = np.sum(currTeam[:,6])\n",
    "    TM = np.sum(currTeam[:,7])\n",
    "    TA = np.sum(currTeam[:,8])\n",
    "    FTM = np.sum(currTeam[:,9])\n",
    "    FTA = np.sum(currTeam[:,10])\n",
    "    OR = np.sum(currTeam[:, 11])\n",
    "    TR = np.sum(currTeam[:,12])\n",
    "    AS = np.sum(currTeam[:,13])\n",
    "    ST = np.sum(currTeam[:,14])\n",
    "    TO = np.sum(currTeam[:,15])\n",
    "    BK = np.sum(currTeam[:,16])\n",
    "    PF = np.sum(currTeam[:,17])\n",
    "    PTS = np.sum(currTeam[:,19])\n",
    "    \n",
    "    MVP = 0\n",
    "    mvpArray = currTeam[:,23]\n",
    "    if True in mvpArray:\n",
    "        MVP = 1\n",
    "        \n",
    "    currTeamStats = [bool(np.array(teams[year])[i,21]), FGM\\\n",
    "                     ,float(FGM)/FGA, TM, float(TM)/TA, FTM\\\n",
    "                     ,float(FTM)/FTA, OR, float(OR)/TR\\\n",
    "                     ,AS, ST, TO, BK, PF, PTS, MVP]\n",
    "    return currTeamStats\n",
    "\n",
    "# create dictionary of NBA teams\n",
    "columns = ['Playoff', 'FGM', 'FG%'\\\n",
    "            ,'3M', '3PT%', 'FTM'\\\n",
    "            ,'FT%', 'OR', 'REB%'\\\n",
    "            ,'AS', 'ST', 'TO'\\\n",
    "            ,'BK', 'PF', 'PTS', 'MVP']\n",
    "nbaSeasons = {}\n",
    "for year in play_years:\n",
    "    teamsDict = {}\n",
    "    for i, team in enumerate(list( teams[year]['key'] )):\n",
    "        currTeam = []\n",
    "        currPlaySeason = np.array( players[year] )\n",
    "        for j in range(currPlaySeason.shape[0]):\n",
    "            if(currPlaySeason[j,1] == team):\n",
    "                currTeam.append(currPlaySeason[j,:])\n",
    "        currTeam = np.array(currTeam)\n",
    "        teamsDict[team] = basketBallTeam(pd.DataFrame(currTeam\\\n",
    "                                                      , columns = players[play_years[0]].columns.tolist()))\n",
    "        \n",
    "        currTeamStats = computeTeamStats(currTeam, i)\n",
    "        \n",
    "        teamsDict[team].totalStats = pd.DataFrame(np.array([currTeamStats])\\\n",
    "                                                  , columns = columns)\n",
    "\n",
    "    nbaSeasons[year] = teamsDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pandas DataFrames of All NBA Teams & All NBA Players\n",
    "\n",
    "Parsing through the nbaSeasons dictionary, we create a dataframe of every NBA player that's ever played in any NBA season. The same process is done for the teams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# boolean flag to indicate not to vertically stack but instead initialize a NumPy array\n",
    "flag = False\n",
    "for year in play_years:\n",
    "    for team in list( teams[year]['key'] ):\n",
    "        if(not flag):\n",
    "            flag = True\n",
    "            allTeamHist = np.array( nbaSeasons[year][team].totalStats )\n",
    "            allPlayHist = np.array( nbaSeasons[year][team].players )\n",
    "            continue\n",
    "        allTeamHist = np.vstack( (allTeamHist, np.array(nbaSeasons[year][team].totalStats) ) )\n",
    "        allPlayHist = np.vstack( (allPlayHist, np.array(nbaSeasons[year][team].players) ) )\n",
    "\n",
    "columnsTeam = columns\n",
    "allTeamHist = pd.DataFrame(allTeamHist, columns = columnsTeam)\n",
    "allTeamHist = allTeamHist.dropna()\n",
    "allPlayHist = pd.DataFrame(allPlayHist, columns = players[play_years[0]].columns.tolist() )\n",
    "allPlayHist = allPlayHist.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze NBA Team Data\n",
    "### Task I: Overall NBA Team Statistics\n",
    "\n",
    "Let's take a deeper look into the NBA Team data and analyze relationships across seasons. First, we compile a dataframe of total integer stats and average fractional stats for each individual NBA team's franchise history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flag = False\n",
    "for year in play_years:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        teamKeys = np.transpose( np.array( [teams[year]['key']] ) )\n",
    "        continue\n",
    "    teamKeys = np.vstack( (teamKeys, np.transpose( np.array( [teams[year]['key']] ) ) ) )\n",
    "\n",
    "# create a deep copy of allTeamHist in order to not manipulate or lose important data in allTeamHist\n",
    "X = np.array(deepcopy(allTeamHist)) \n",
    "X = pd.DataFrame(X, columns = columns, index = teamKeys.ravel())\n",
    "del X['Playoff']\n",
    "del X['MVP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for computing overall sum of stats for each team (not by season but for entire NBA track starting in 2001)\n",
    "def computeOverallTeamStats(X, team, statNames):\n",
    "    overTeamStats = []\n",
    "    for stat in statNames:\n",
    "        overTeamStats.append( X[X.index == team][stat].sum(axis = 0) )\n",
    "    return np.array(overTeamStats)\n",
    "\n",
    "allStatNames = columnsTeam[1:-1]\n",
    "\n",
    "teamsAlreadyChecked = []\n",
    "flag = False\n",
    "for team in list(X.index):\n",
    "    if team in teamsAlreadyChecked:\n",
    "        continue\n",
    "    else:\n",
    "        teamsAlreadyChecked.append(team)\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            overTeamStats = computeOverallTeamStats(X, team, allStatNames)\n",
    "            continue\n",
    "        currTeamStats = computeOverallTeamStats(X, team, allStatNames)\n",
    "        overTeamStats = np.vstack( (overTeamStats, currTeamStats) )\n",
    "\n",
    "overTeamStatsDF = pd.DataFrame(overTeamStats, columns = columnsTeam[1:-1], index = teamsAlreadyChecked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we obtain the plot of all the integer stats to analyze the team's total sum of franchise stats. Using the Python library, plotly, we obtain an organized (and visually asthetic), multi-bar graph.\n",
    "\n",
    "- Integer Stats\n",
    "    - Field Goals Made (FGM)\n",
    "    - Three Pointers Made (3M)\n",
    "    - Free Throws Made (FTM)\n",
    "    - Offensive Rebounds (OR)\n",
    "    - Assists (AS)\n",
    "    - Steals (ST)\n",
    "    - Turnovers (TO)\n",
    "    - Blocks (BK)\n",
    "    - Personal Fouls (PF)\n",
    "    - Points Made (PTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/18.embed\" height=\"800px\" width=\"1500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain integer stat labels\n",
    "intStats = overTeamStatsDF.columns.tolist()\n",
    "removeFields = ['FG%', '3PT%', 'FT%', 'REB%']\n",
    "for field in removeFields:\n",
    "    intStats.remove(field)\n",
    "\n",
    "# extract all integer data and create multicolumn barcharts of overall integer stats\n",
    "data = []\n",
    "for team in list(overTeamStatsDF.index):\n",
    "    teamStats = np.array(overTeamStatsDF[overTeamStatsDF.index == team]).ravel().tolist()\n",
    "    for fracLoc in [1, 2, 3, 4]:\n",
    "        teamStats.remove(teamStats[fracLoc])\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = intStats,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Overall Total Sum of Team Integer Statistics (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'Integer Statistics'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Integer Score'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=1500 #width in pixels\n",
    "fig.layout.height = 800\n",
    "py.iplot(fig, filename = 'overall team integer features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we plot the fractional stats the same manner we did the integer stats.\n",
    "\n",
    "- Fractional Stats\n",
    "    - Field Goal Percentage (FG%)\n",
    "    - Three Point Percentage (3PT%)\n",
    "    - Free Throw Percentage (FT%)\n",
    "    - Offensive Rebound Perentage (REB%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/20.embed\" height=\"750px\" width=\"1500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain fractional stats (same as integer stats process)\n",
    "fracStats = overTeamStatsDF.columns.tolist()\n",
    "removeFields = ['FGM', '3M', 'FTM', 'OR', 'AS', 'ST', 'TO', 'BK', 'PF', 'PTS']\n",
    "for field in removeFields:\n",
    "    fracStats.remove(field)\n",
    "\n",
    "# repeat for fractional stats\n",
    "data = []\n",
    "for team in list(overTeamStatsDF.index):\n",
    "    teamStats = itemgetter(*[1,3,5,7])(np.array(\n",
    "        overTeamStatsDF[overTeamStatsDF.index == team]).ravel().tolist())\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = fracStats,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Overall Average of Team Fraction Statistics (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'Fractional Statistics'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Percentage Score'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=1500 #width in pixels\n",
    "fig.layout.height = 750\n",
    "py.iplot(fig, filename = 'overall team fractional features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze NBA Team Data\n",
    "### Task II: Analyze Individual NBA Team Statistics By Year\n",
    "For our next analysis, we want to observe the behavior of NBA teams through the different seasons in our dataset (2001-2002 through 2015-2016). First, we add the New Orleans teams to the first three seasons of our NBA dataset, with stats. of 0 across the board for all three years, since the New Orleans teams were not introduced until the 2004-2005 NBA Season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create deepcopy of X in order to not damage data\n",
    "Xarr = deepcopy(X)\n",
    "\n",
    "# convert to NumPy array\n",
    "Xarr = np.array(Xarr)\n",
    "\n",
    "# add NOrleans team with stats of 0 across the board for the first three seasons\n",
    "for i in range(3):\n",
    "    Xarr = np.vstack((np.array([0 for i in range(Xarr.shape[1])]), Xarr ))\n",
    "\n",
    "# reconvert back to dataframe with newly added NOrleans team stats\n",
    "XarrDF = pd.DataFrame(Xarr, columns = X.columns.tolist(), index = ['nor']*3 + X.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task I: Team Field Goals per Season\n",
    "Next, we construct our bar graph to analyze the performance of all NBA teams throughout each of the NBA seasons in our dataset. The first feature we analyze is the numebr of field goals a team makes in each NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract team years list where each entry is a string in the form of: 2001-2002\n",
    "teamYears = []\n",
    "for year in play_years:\n",
    "    teamYears.append(str(year + 2000) + '-' + str(year + 2001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/22.embed\" height=\"400px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot field goals\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['FGM']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Field Goals Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Number of Field Goals Made in Season'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 400\n",
    "py.iplot(fig, filename = 'field goals made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task II: Team Three Pointers per Season\n",
    "The folllowing feature we analyze is the number fo three-pointers a team scores in an season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/24.embed\" height=\"550px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot threes made\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['3M']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Threes Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Threes Made in a Season'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 550\n",
    "py.iplot(fig, filename = 'threes made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task III: Team Assists per Season\n",
    "Afterwards, we look closely at the number of assists per NBA season for each NBA team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/26.embed\" height=\"550px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot assists made per team\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['AS']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Assists per Teams per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Assists in a Season'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 550\n",
    "py.iplot(fig, filename = 'assists per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task IV: Points Scored per Season\n",
    "The next feature we analyze is the number of points a team scores in each NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/28.embed\" height=\"550px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot points scored per team\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['PTS']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Points Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Points Made in a Season'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 550\n",
    "py.iplot(fig, filename = 'points made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task V: Team Free-Throws Made per Season\n",
    "The next feature we analyze is the number of free-throws a team scores in each NBA season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/30.embed\" height=\"550px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot free throws made per team\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['FTM']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Free-Throws Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Free-Throws Made in a Season'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 550\n",
    "py.iplot(fig, filename = 'free throws made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-Task VI: Team Steals per Season\n",
    "The next feature we analyze is the number of steals teams commit per season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/32.embed\" height=\"550px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot steals made per team\n",
    "\n",
    "data = []\n",
    "for team in teams[year]['key']:\n",
    "    teamStats = np.array(XarrDF[XarrDF.index == team]['ST']).tolist()\n",
    "\n",
    "    trace = go.Bar(\n",
    "        x = teamYears,\n",
    "        y = teamStats,\n",
    "        name = team\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'group',\n",
    "    title = 'Steals Made by Teams Per Season (2001-2016)',\n",
    "    xaxis = dict(\n",
    "        title = 'NBA Season'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'Steals Made in a Season'\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig.layout.width=2500 #width in pixels\n",
    "fig.layout.height = 550\n",
    "py.iplot(fig, filename = 'steals made per season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting NBA Playoff Teams\n",
    "## Sub-process I: Determining the Statistical Significance of Team Stats to Playoff Status\n",
    "For the first prediction, we will focus on predicting a whether an NBA team is cable of becoming a Playoff contender.\n",
    "\n",
    "In this initial step, we focus on determining the statistical significance of features to NBA-Playoff contention. First, we look for the index of every NBA team that has been in the NBA-Playoffs during their respective season and those that weren't and store these indices in seperate NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# record the indices of playoff teams, and non playoff teams\n",
    "\n",
    "Iplay = np.where( np.array(allTeamHist['Playoff']) == True )[0]\n",
    "Inon = np.where( np.array(allTeamHist['Playoff']) == False )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a deep copy of the allTeamHist dataframe, but remove irrelevant features such as:\n",
    "- Playoff Indication (Playoff)\n",
    "\n",
    "because this is what we're trying to predict. In other words, we remove the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flag = False\n",
    "for year in play_years:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        teamNames = np.transpose( np.array( [teams[year]['team']] ) )\n",
    "        continue\n",
    "    teamNames = np.vstack( (teamNames, np.transpose( np.array( [teams[year]['team']] ) ) ) )\n",
    "X = np.hstack( ( teamNames, np.array(deepcopy(allTeamHist)) ) )\n",
    "X = pd.DataFrame(X, columns = [\"Team\"] + columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/8.embed\" height=\"260px\" width=\"2500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only plot the first 6 rows of teams to save computation and plotting time (takes very long to plot ALL teams)\n",
    "\n",
    "allNBATeamsTable = FF.create_table(X.head(6))\n",
    "allNBATeamsTable.layout.width=2500 #width in pixels\n",
    "allNBATeamsTable.layout.margin.update({'t':75, 'l':50})\n",
    "allNBATeamsTable.layout.update({'title': 'All NBA Team Statistics (First 6)'})\n",
    "py.iplot(allNBATeamsTable, filename = 'All NBA Team Stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X['Team']\n",
    "del X['Playoff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we import the ztest function from the Python statsmodel.stats.weightstats module to perform a Z-test on our features. We do this to determine the significance of our features in the determination of the NBA-Playoff contenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute Z-Test on all features and compute statistical significance of each feature\n",
    "\n",
    "statDF = []\n",
    "for label in X.columns.tolist():\n",
    "    play = np.array(X[label])[Iplay]\n",
    "    non = np.array(X[label])[Inon]\n",
    "    stat, pval = ztest(play, non, 0, 'larger')\n",
    "    statDF.append( [label, stat, pval] )\n",
    "    \n",
    "statDF = pd.DataFrame(statDF, columns = ['Feature', 'statistic', 'p-val'])\n",
    "statDF = statDF.sort_values (['p-val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/10.embed\" height=\"530px\" width=\"600px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tabulate results of Z-Test\n",
    "allTeamsZtestTable = FF.create_table(statDF)\n",
    "allTeamsZtestTable.layout.width = 600\n",
    "allTeamsZtestTable.layout.margin.update({'t':75, 'l':50})\n",
    "allTeamsZtestTable.layout.update({'title': 'Features Statistical Significance'})\n",
    "py.iplot(allTeamsZtestTable, filename = 'Feat Stat Sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis shows that features such as:\n",
    "- Offensive Rebounding Percentage (REB%)\n",
    "- Personal Fouls (PF)\n",
    "- Turnovers (TO)\n",
    "- Offensive Rebounds (OR)\n",
    "- Free Throw Percentage (FT%)\n",
    "\n",
    "do not have a real significance in the determination of the NBA-Playoff contention. Therefore, we remove these features from our feature matrix since they probabilistically reject our null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X['REB%']\n",
    "del X['PF']\n",
    "del X['TO']\n",
    "del X['OR']\n",
    "del X['FT%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process II: Developing Training Data\n",
    "Now, we prepare a vector of boolean values indicating whether a team was an NBA-Playoff contender or not. We also cast the dataframe of predictors we have to a NumPy array type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelazcona/miniconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning:\n",
      "\n",
      "Data with input dtype object was converted to float64 by the scale function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = list( deepcopy(allTeamHist['Playoff']) )\n",
    "Xs = preprocessing.scale(np.array(X))\n",
    "\n",
    "nsamp = Xs.shape[0]\n",
    "ntr = int(0.7*nsamp)\n",
    "nts = nsamp - ntr\n",
    "\n",
    "Xtr = Xs[:ntr,:]\n",
    "ytr = y[:ntr]\n",
    "\n",
    "Xts = Xs[ntr:,:]\n",
    "yts = y[ntr:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Task I: Train Classifier on Entire Dataset\n",
    "Next, we develop a logistic classifier model using sklearn to predict NBA Playoff Contenders. First we train our logistic regression classifier on all of the NBA teams that have ever existed. Using this, we test out a range of regularization strengths, $C$, to determine what the best one is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=  1.0000e-02 \t l1-err = 5.4167e-01 \t l2-err = 2.9808e-01 \t err = 2.9808e-01\n",
      "C=  3.7276e-02 \t l1-err = 2.9808e-01 \t l2-err = 2.7244e-01 \t err = 2.7244e-01\n",
      "C=  1.3895e-01 \t l1-err = 2.6282e-01 \t l2-err = 2.7244e-01 \t err = 2.7244e-01\n",
      "C=  5.1795e-01 \t l1-err = 2.5962e-01 \t l2-err = 2.6603e-01 \t err = 2.6603e-01\n",
      "C=  1.9307e+00 \t l1-err = 2.7564e-01 \t l2-err = 2.7244e-01 \t err = 2.7244e-01\n",
      "C=  7.1969e+00 \t l1-err = 2.7244e-01 \t l2-err = 2.7244e-01 \t err = 2.7244e-01\n",
      "C=  2.6827e+01 \t l1-err = 2.6923e-01 \t l2-err = 2.6923e-01 \t err = 2.6923e-01\n",
      "C=  1.0000e+02 \t l1-err = 2.6923e-01 \t l2-err = 2.6923e-01 \t err = 2.6923e-01\n",
      "C=  3.7276e+02 \t l1-err = 2.6923e-01 \t l2-err = 2.6923e-01 \t err = 2.6923e-01\n",
      "C=  1.3895e+03 \t l1-err = 2.6923e-01 \t l2-err = 2.6923e-01 \t err = 2.6923e-01\n",
      "C=  5.1795e+03 \t l1-err = 2.6923e-01 \t l2-err = 2.6923e-01 \t err = 2.6923e-01\n",
      "C=  1.9307e+04 \t l1-err = 2.6923e-01 \t l2-err = 2.6923e-01 \t err = 2.6923e-01\n",
      "C=  7.1969e+04 \t l1-err = 2.6923e-01 \t l2-err = 2.6923e-01 \t err = 2.6923e-01\n",
      "C=  2.6827e+05 \t l1-err = 2.6923e-01 \t l2-err = 2.6923e-01 \t err = 2.6923e-01\n",
      "C=  1.0000e+06 \t l1-err = 2.6923e-01 \t l2-err = 2.6923e-01 \t err = 2.6923e-01\n"
     ]
    }
   ],
   "source": [
    "Cvals = np.logspace(-2,6,15)\n",
    "\n",
    "# initialize list of error rates for each regularization strength, C\n",
    "err_l1 = []\n",
    "err_l2 = []\n",
    "err = []\n",
    "\n",
    "# initialize minimum error rate of 100%\n",
    "l1_err_min = 1\n",
    "l2_err_min = 1\n",
    "err_min = 1\n",
    "\n",
    "# parse through C values, train the logistic classifier for each C value, and compute the error rate of the model\n",
    "# for the corresponding C value\n",
    "for C in Cvals:\n",
    "    \n",
    "    # create instance of logistic classifier (l1-penalized, l2-penalized, and unregularized)\n",
    "    logregl1 = linear_model.LogisticRegression(penalty = 'l1', C = C)\n",
    "    logregl2 = linear_model.LogisticRegression(penalty = 'l2', C = C)\n",
    "    logreg = linear_model.LogisticRegression(C = C)\n",
    "    \n",
    "    # train model with training data\n",
    "    logregl1.fit(Xtr, ytr)\n",
    "    logregl2.fit(Xtr, ytr)\n",
    "    logreg.fit(Xtr, ytr)\n",
    "    \n",
    "    # make predictions with each model\n",
    "    y_hat_l1 = logregl1.predict(Xtr)\n",
    "    y_hat_l2 = logregl2.predict(Xtr)\n",
    "    y_hat = logreg.predict(Xtr)\n",
    "    \n",
    "    # calculate error rate of the model's prediction and ground truth values\n",
    "    err_i_l1 = np.mean(y_hat_l1 != ytr)\n",
    "    err_i_l2 = np.mean(y_hat_l2 != ytr)\n",
    "    err_i = np.mean(y_hat != ytr)\n",
    "    \n",
    "    # append error rates\n",
    "    err_l1.append(err_i_l1)\n",
    "    err_l2.append(err_i_l2)\n",
    "    err.append(err_i)\n",
    "    \n",
    "    # keep track of C value that gives the smallest error across all three models\n",
    "    if (l1_err_min > err_i_l1) and (l2_err_min > err_i_l2) and (err_min > err_i):\n",
    "        l1_err_min = err_i_l1\n",
    "        l2_err_min = err_i_l2\n",
    "        err_min = err_i\n",
    "        C_min = C\n",
    "    \n",
    "    print(\"C={0:12.4e} \\t l1-err = {1:10.4e} \\t l2-err = {2:10.4e} \\t err = {3:10.4e}\".format(C\\\n",
    "        , err_i_l1, err_i_l2, err_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our analysis, we keep the regularization strength, $C$, which minimizes the error in predicting the NBA-Playoff contenders for all three of our models.\n",
    "\n",
    "Now, we test our trained model to predict NBA-Playoff contenders in each NBA season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Task II: Use Entire-Trained-Classifier to Predict Playoffs in Each NBA Season\n",
    "Using the regularization strength, $C$, with the least error in predicting the NBA-Playoff contender, we now use our traiend classifier to predict Playoff teams in each individual NBA Season, by iterating through each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C_min' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-695670cd40ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# training data from all the previous seasons before the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogregl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlogregl2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'C_min' is not defined"
     ]
    }
   ],
   "source": [
    "# Use logistic classifier that predicts with minimal error to predict playoff contenders per season, with\n",
    "# training data from all the previous seasons before the testing set\n",
    "\n",
    "logregl1 = linear_model.LogisticRegression(penalty = 'l1', C = C_min)\n",
    "logregl2 = linear_model.LogisticRegression(penalty = 'l2', C = C_min)\n",
    "logreg = linear_model.LogisticRegression(C = C_min)\n",
    "\n",
    "logregl1.fit(Xtr, ytr)\n",
    "logregl2.fit(Xtr, ytr)\n",
    "logreg.fit(Xtr, ytr)\n",
    "\n",
    "acc_l1 = []\n",
    "acc_l2 = []\n",
    "acc = []\n",
    "\n",
    "for year in play_years:\n",
    "    currSeason = nbaSeasons[year]\n",
    "    \n",
    "    flag = False\n",
    "    for team in teams[year]['key']:\n",
    "        if(not flag):\n",
    "            flag = True\n",
    "            teamArr = np.array(currSeason[team].totalStats)\n",
    "            continue\n",
    "        teamArr = np.vstack((teamArr,np.array(currSeason[team].totalStats)))\n",
    "\n",
    "    X = pd.DataFrame(teamArr, columns = columns)\n",
    "    y = list(deepcopy(X['Playoff']))\n",
    "    del_labels = ['REB%', 'PF', 'TO', 'OR', 'FT%', 'Playoff']\n",
    "    for label in del_labels:\n",
    "        del X[label]\n",
    "    \n",
    "    Xs = preprocessing.scale(X)\n",
    "    \n",
    "    y_hat_l1 = logregl1.predict_proba(Xs)\n",
    "    y_hat_l2 = logregl2.predict_proba(Xs)\n",
    "    y_hat = logreg.predict_proba(Xs)\n",
    "    \n",
    "    westPlayoffTeams = np.array(teams[year]['team'])[np.where(np.array(y) == True and teams[year]['Conference'] == 'West')]\n",
    "    eastPlayoffTeams = np.array(teams[year]['team'])[np.where(np.array(y) == True and teams[year]['Conference'] == 'East')]\n",
    "    \n",
    "    sortedPlayPred_l1 = np.argsort(y_hat_l1[:,1])\n",
    "    predictedTeams_l1 = np.array(teams[year]['team'])[sortedPlayPred_l1[-16:]]\n",
    "    \n",
    "    sortedPlayPred_l2 = np.argsort(y_hat_l2[:,1])\n",
    "    predictedTeams_l2 = np.array(teams[year]['team'])[sortedPlayPred_l2[-16:]]\n",
    "    \n",
    "    sortedPlayPred = np.argsort(y_hat[:,1])\n",
    "    predictedTeams = np.array(teams[year]['team'])[sortedPlayPred[-16:]]\n",
    "    \n",
    "    corr_l1 = 0\n",
    "    corr_l2 = 0\n",
    "    corr = 0\n",
    "    i = 0\n",
    "    \n",
    "    for predict_l1, predict_l2, predict in zip(predictedTeams_l1, predictedTeams_l2, predictedTeams):\n",
    "        i += 1\n",
    "        if predict_l1 in westPlayoffTeams or predict_l1 in eastPlayoffTeams:\n",
    "            corr_l1 += 1\n",
    "        \n",
    "        if predict_l2 in westPlayoffTeams or predict_l2 in eastPlayoffTeams:\n",
    "            corr_l2 += 1\n",
    "        \n",
    "        if predict in westPlayoffTeams or predict in eastPlayoffTeams:\n",
    "            corr += 1\n",
    "    \n",
    "    acc_i_l1 = float(corr_l1)/i\n",
    "    acc_i_l2 = float(corr_l2)/i\n",
    "    acc_i = float(corr)/i\n",
    "    \n",
    "    acc_l1.append(acc_i_l1)\n",
    "    acc_l2.append(acc_i_l2)\n",
    "    acc.append(acc_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using, our predictions and ground truth data, we tabulate the accuracy of our entire-dataset-trained classifier for predicting the NBA-Playoff teams in each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create NumPy array of team years and accuracies in order to horizontally stack them\n",
    "playYearsString = np.transpose( np.array([teamYears]) )\n",
    "\n",
    "acc_l1 = np.transpose( np.array([acc_l1]) )\n",
    "acc_l2 = np.transpose( np.array([acc_l2]) )\n",
    "acc = np.transpose( np.array([acc]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/12.embed\" height=\"530px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totAccTable = FF.create_table( pd.DataFrame( np.hstack((playYearsString, acc_l1, acc_l2, acc))\\\n",
    "                                            , columns = ['NBA Season'\n",
    "                                                         , 'l1-Predict Acc.'\\\n",
    "                                                         , 'l2-Predict Acc.'\\\n",
    "                                                         , 'Un-normalized Predict Acc.']) )\n",
    "\n",
    "totAccTable.layout.width = 800\n",
    "totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "totAccTable.layout.update({'title': 'Accuracy of Total-Trained Model Over Each NBA Season'})\n",
    "py.iplot(totAccTable, filename = 'totAccTable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Focus III: Create Dictionary of NBA Team Stats by Season\n",
    "Next, we create a dictionary of NBA teams by the season, with each entry being the a dataframe of seasonal stats for a team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create ordered dictionary of NBA stats by season\n",
    "teamsDict = OrderedDict()\n",
    "for year in play_years:\n",
    "    flag = False\n",
    "    seasonTeams = []\n",
    "    for team in teams[year]['key']:\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            seasonTeams = np.array(nbaSeasons[year][team].totalStats).ravel()\n",
    "            continue\n",
    "        seasonTeams = np.vstack( (seasonTeams, np.array(nbaSeasons[year][team].totalStats).ravel()) )\n",
    "    \n",
    "    seasonTeams = pd.DataFrame( seasonTeams, columns = columnsTeam, index = teams[year]['key'].ravel().tolist() )\n",
    "    \n",
    "    # delete irrelevant features as described by the Z-Test\n",
    "    del seasonTeams['REB%']\n",
    "    del seasonTeams['PF']\n",
    "    del seasonTeams['TO']\n",
    "    del seasonTeams['OR']\n",
    "    del seasonTeams['FT%']\n",
    "    teamsDict[year] = seasonTeams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Focus IV: Train Classifier With All Years of NBA Team Data Prior to Each Season\n",
    "In this focus area, we create two lists:\n",
    "- Training Data List\n",
    "- Testing Data List\n",
    "\n",
    "The list organization is described by the following example:\n",
    "Ex:\n",
    "- Testing on 2013-2014 NBA Season\n",
    "    - Training Data contains all team information from 2001-2013\n",
    "    - Testing Data contains all team information for 2013-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compileTrainData(teamsDict, year):\n",
    "    flag = False\n",
    "    for i in range(1,year+1):\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            Xtr = np.array(teamsDict[i])\n",
    "            continue\n",
    "        Xtr = np.vstack( (Xtr, np.array(teamsDict[i]) ) )\n",
    "    return Xtr\n",
    "    \n",
    "trainingFeatureSets = []\n",
    "trainingTargetSets = []\n",
    "for year in play_years[:-1]:\n",
    "    Xtr = compileTrainData(teamsDict, year)\n",
    "    ytr = deepcopy(Xtr[:,0])\n",
    "    Xtr = Xtr[:,1:]\n",
    "    \n",
    "    trainingFeatureSets.append(preprocessing.scale(Xtr))\n",
    "    trainingTargetSets.append(ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process III: Logistic Regression Classifier\n",
    "### Focus V: Predict NBA Playoff Contenders in Each Season & Determine Accuracy\n",
    "Next, we use our trained model to predict NBA-Playoff contenders in each NBA season and compute the accuracy of our prediction for each season. Afterwards, we tabulate our results to analyze the relationship between progressively training the model with more data each season and predicting NBA-Playoff contenders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accl1 = []\n",
    "accl2 = []\n",
    "acc = []\n",
    "\n",
    "for i, year in enumerate(play_years[1:]):\n",
    "    Xts = np.array(teamsDict[year])\n",
    "    yts = deepcopy(Xts[:,0])\n",
    "    Xts =  preprocessing.scale(Xts[:,1:])\n",
    "    \n",
    "    logregl1 = linear_model.LogisticRegression(penalty = 'l1', C = C_min)\n",
    "    logregl2 = linear_model.LogisticRegression(penalty = 'l2', C = C_min)\n",
    "    logreg = linear_model.LogisticRegression(C = C_min)\n",
    "\n",
    "    logregl1.fit( trainingFeatureSets[i], trainingTargetSets[i] )\n",
    "    logregl2.fit( trainingFeatureSets[i], trainingTargetSets[i] )\n",
    "    logreg.fit( trainingFeatureSets[i], trainingTargetSets[i] )\n",
    "    \n",
    "    yts_hat_l1 = logregl1.predict_proba(Xts)\n",
    "    yts_hat_l2 = logregl2.predict_proba(Xts)\n",
    "    yts_hat = logreg.predict_proba(Xts)\n",
    "    \n",
    "    playoffTeams = np.array(teams[year]['team'])[np.where(np.array(yts) == True)]\n",
    "    \n",
    "    sortedPlayPred_l1 = np.argsort(yts_hat_l1[:,1])\n",
    "    predictedTeams_l1 = np.array(teams[year]['team'])[sortedPlayPred_l1[-16:]]\n",
    "    \n",
    "    sortedPlayPred_l2 = np.argsort(yts_hat_l2[:,1])\n",
    "    predictedTeams_l2 = np.array(teams[year]['team'])[sortedPlayPred_l2[-16:]]\n",
    "    \n",
    "    sortedPlayPred = np.argsort(yts_hat[:,1])\n",
    "    predictedTeams = np.array(teams[year]['team'])[sortedPlayPred[-16:]]\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    corr_l1 = 0\n",
    "    corr_l2 = 0\n",
    "    corr = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for predict_l1, predict_l2, predict in zip(predictedTeams_l1, predictedTeams_l2, predictedTeams):\n",
    "        i += 1\n",
    "        if predict_l1 in playoffTeams:\n",
    "            corr_l1 += 1\n",
    "        \n",
    "        if predict_l2 in playoffTeams:\n",
    "            corr_l2 += 1\n",
    "        \n",
    "        if predict in playoffTeams:\n",
    "            corr += 1\n",
    "    \n",
    "    acc_i_l1 = float(corr_l1)/i\n",
    "    acc_i_l2 = float(corr_l2)/i\n",
    "    acc_i = float(corr)/i\n",
    "\n",
    "    accl1.append(acc_i_l1)\n",
    "    accl2.append(acc_i_l2)\n",
    "    acc.append(acc_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/34.embed\" height=\"500px\" width=\"1000px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainYears = []\n",
    "testYears = []\n",
    "\n",
    "for curr in play_years[1:]:\n",
    "    trainYears.append( str(2001) + '-' + str(2000 + curr) )\n",
    "    testYears.append( str(2000 + curr) + '-' + str(2001 + curr) )\n",
    "\n",
    "trainYears = np.transpose(np.array([trainYears]))\n",
    "testYears = np.transpose(np.array([testYears]))\n",
    "\n",
    "accl1 = np.transpose( np.array([accl1]) )\n",
    "accl2 = np.transpose( np.array([accl2]) )\n",
    "acc = np.transpose( np.array([acc]) )\n",
    "\n",
    "totAccTable = FF.create_table( pd.DataFrame( np.hstack((trainYears, testYears, accl1, accl2, acc))\\\n",
    "                                            , columns = ['Train Years', 'Test NBA Season'\\\n",
    "                                                         , 'l1-Predict Acc.'\\\n",
    "                                                         , 'l2-Predict Acc.'\\\n",
    "                                                         , 'Un-normalized Predict Acc.']) )\n",
    "\n",
    "totAccTable.layout.width = 1000\n",
    "totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "totAccTable.layout.update({'title': 'Accuracy of Progressively-Trained Model Over Each NBA Season'})\n",
    "py.iplot(totAccTable, filename = 'progAccTable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process IV: C-Support Vector Classification\n",
    "### Focus I: Reformat Entire Dataset for Total Training\n",
    "\n",
    "After our analysis of the logistic regression classifier, we move forward to analyzing the accuracy of classifications using support vectore machines and c-support vector classification.\n",
    "\n",
    "First, we reformat the Entire Dataset for total model training across the dataset to analyze the best regularization strength, $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allTeamHist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-02c18ec85427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mteamNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mteamNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mteams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'team'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mteamNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallTeamHist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Team\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'allTeamHist' is not defined"
     ]
    }
   ],
   "source": [
    "flag = False\n",
    "for year in play_years:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        teamNames = np.transpose( np.array( [teams[year]['team']] ) )\n",
    "        continue\n",
    "    teamNames = np.vstack( (teamNames, np.transpose( np.array( [teams[year]['team']] ) ) ) )\n",
    "X = np.hstack( ( teamNames, np.array(deepcopy(allTeamHist)) ) )\n",
    "X = pd.DataFrame(X, columns = [\"Team\"] + columns)\n",
    "\n",
    "del X['Team']\n",
    "del X['Playoff']\n",
    "del X['REB%']\n",
    "del X['PF']\n",
    "del X['TO']\n",
    "del X['OR']\n",
    "del X['FT%']\n",
    "\n",
    "y = list( deepcopy(allTeamHist['Playoff']) )\n",
    "Xs = preprocessing.scale(np.array(X))\n",
    "\n",
    "nsamp = Xs.shape[0]\n",
    "ntr = int(0.8*nsamp)\n",
    "nts = nsamp - ntr\n",
    "\n",
    "Xtr = Xs[:ntr,:]\n",
    "ytr = y[:ntr]\n",
    "\n",
    "Xts = Xs[ntr:,:]\n",
    "yts = y[ntr:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process IV: C-Support Vector Classification\n",
    "### Focus II: Intialize SVM Model Instance and Test Seperate Regularization Strengths on Entire Datatset Prediction\n",
    "Afterwards, we intialize an support vector machine model instance and test our classifier across several regularization strengths, $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cvals = np.logspace(-2,5,10)\n",
    "\n",
    "err_lin = []\n",
    "err_rbf = []\n",
    "err_poly = []\n",
    "err_sig = []\n",
    "\n",
    "lin_err_min = 1\n",
    "rbf_err_min = 1\n",
    "poly_err_min = 1\n",
    "sig_err_min = 1\n",
    "\n",
    "flag = False\n",
    "for C in Cvals:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        C_min = C\n",
    "        \n",
    "    svm_lin = svm.SVC(kernel = 'linear', C = C)\n",
    "    svm_rbf = svm.SVC(kernel = 'rbf', C = C)\n",
    "    svm_poly = svm.SVC(kernel = 'poly', C = C)\n",
    "    svm_sig = svm.SVC(kernel = 'sigmoid', C = C)\n",
    "    \n",
    "    svm_lin.fit(Xs, y)\n",
    "    svm_rbf.fit(Xs, y)\n",
    "    svm_poly.fit(Xs, y)\n",
    "    svm_sig.fit(Xs, y)\n",
    "    \n",
    "    y_hat_lin = svm_lin.predict(Xtr)\n",
    "    y_hat_rbf = svm_rbf.predict(Xtr)\n",
    "    y_hat_poly = svm_poly.predict(Xtr)\n",
    "    y_hat_sig = svm_sig.predict(Xtr)\n",
    "    \n",
    "    err_i_lin = np.mean(y_hat_lin != ytr)\n",
    "    err_i_rbf = np.mean(y_hat_rbf != ytr)\n",
    "    err_i_poly = np.mean(y_hat_poly != ytr)\n",
    "    err_i_sig = np.mean(y_hat_sig != ytr)\n",
    "    \n",
    "    err_lin.append(err_i_lin)\n",
    "    err_rbf.append(err_i_rbf)\n",
    "    err_poly.append(err_i_poly)\n",
    "    err_sig.append(err_i_sig)\n",
    "    \n",
    "    if (lin_err_min > err_i_lin) or \\\n",
    "    (rbf_err_min > err_i_rbf) or \\\n",
    "    (poly_err_min > err_i_poly) or (sig_err_min > err_i_sig):\n",
    "        lin_err_min = err_i_lin\n",
    "        rbf_err_min = err_i_rbf\n",
    "        poly_err_min = err_i_poly\n",
    "        sig_err_min = err_i_sig\n",
    "        C_min = C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process IV: C-Support Vector Classification\n",
    "### Focus III: Tabulate & Analyze Entire Dataset Training Errors\n",
    "Next, we tabulate our results and analyze the errors based on the regualrization strengths on each of our SVM classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/36.embed\" height=\"380px\" width=\"900px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CvalsArr = np.transpose( np.array([Cvals]))\n",
    "\n",
    "err_linArr = np.transpose( np.array([err_lin]) )\n",
    "err_rbfArr = np.transpose( np.array([err_rbf]) )\n",
    "err_polyArr = np.transpose( np.array([err_poly]) )\n",
    "err_sigArr = np.transpose( np.array([err_sig]) )\n",
    "\n",
    "totAccTable = FF.create_table( pd.DataFrame( np.hstack((CvalsArr, err_linArr, err_rbfArr, err_polyArr, err_sigArr))\\\n",
    "                                            , columns = ['Regularizaion Strengths, C', 'linear SVM err'\\\n",
    "                                                         , 'rbf SVM err'\\\n",
    "                                                         , 'poly SVM err'\\\n",
    "                                                         , 'sigmoid SVM err']) )\n",
    "\n",
    "totAccTable.layout.width = 900\n",
    "totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "totAccTable.layout.update({'title': 'Support Vector Machine Classifier Error Rates'})\n",
    "py.iplot(totAccTable, filename = 'overSVMTable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process IV: C-Support Vector Classification\n",
    "### Focus IV: Use SVM's with Minimal Errors to Progressively Predict Throughout NBA Seasons\n",
    "Based on our tabulated results, we seee that using radial basis function and 3rd-degree polynomial kernels yield minimal errors when the regularization strength, $C$, is approximately equal to:\n",
    "\n",
    "$ C = 10^5 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileTrainData(teamsDict, year):\n",
    "    flag = False\n",
    "    for i in range(1,year+1):\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            Xtr = np.array(teamsDict[i])\n",
    "            continue\n",
    "        Xtr = np.vstack( (Xtr, np.array(teamsDict[i]) ) )\n",
    "    return Xtr\n",
    "    \n",
    "trainingFeatureSets = []\n",
    "trainingTargetSets = []\n",
    "for year in play_years[:-1]:\n",
    "    Xtr = compileTrainData(teamsDict, year)\n",
    "    ytr = deepcopy(Xtr[:,0])\n",
    "    Xtr = Xtr[:,1:]\n",
    "    \n",
    "    trainingFeatureSets.append(preprocessing.scale(Xtr))\n",
    "    trainingTargetSets.append(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_rbf = []\n",
    "acc_poly = []\n",
    "for i, year in enumerate(play_years[1:]):\n",
    "    Xts = np.array(teamsDict[year])\n",
    "    yts = deepcopy(Xts[:,0])\n",
    "    Xts =  preprocessing.scale(Xts[:,1:])\n",
    "    \n",
    "    svm_rbf = svm.SVC(kernel = 'rbf', C = C_min)\n",
    "    svm_poly = svm.SVC(kernel = 'poly', C = C_min)\n",
    "\n",
    "    svm_rbf.fit( trainingFeatureSets[i], trainingTargetSets[i] )\n",
    "    svm_poly.fit( trainingFeatureSets[i], trainingTargetSets[i] )\n",
    "    \n",
    "    yts_hat_rbf = svm_rbf.predict(Xts)\n",
    "    yts_hat_poly = svm_poly.predict(Xts)\n",
    "    \n",
    "        \n",
    "    acc_i_rbf = np.mean(yts_hat_rbf == yts)\n",
    "    acc_i_poly = np.mean(yts_hat_poly == yts)\n",
    "    \n",
    "    acc_rbf.append(acc_i_rbf)\n",
    "    acc_poly.append(acc_i_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainYears = []\n",
    "testYears = []\n",
    "\n",
    "for curr in play_years[1:]:\n",
    "    trainYears.append( str(2001) + '-' + str(2000 + curr) )\n",
    "    testYears.append( str(2000 + curr) + '-' + str(2001 + curr) )\n",
    "\n",
    "trainYears = np.transpose(np.array([trainYears]))\n",
    "testYears = np.transpose(np.array([testYears]))\n",
    "\n",
    "acc_rbf = np.transpose( np.array([acc_rbf]) )\n",
    "acc_poly = np.transpose( np.array([acc_poly]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/38.embed\" height=\"500px\" width=\"700px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totAccTable = FF.create_table( pd.DataFrame( np.hstack((trainYears, testYears, acc_rbf, acc_poly))\\\n",
    "                                            , columns = ['Train Years', 'Test NBA Season'\\\n",
    "                                                         , 'rbf SVM Predict Acc.'\\\n",
    "                                                         , 'poly SVM Predict Acc.']) )\n",
    "\n",
    "totAccTable.layout.width = 700\n",
    "totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "totAccTable.layout.update({'title': 'Accuracy of Progressively-Trained SVM Model Over Each NBA Season'})\n",
    "py.iplot(totAccTable, filename = 'progAccSVMTable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process V: Random Forest Classification\n",
    "### Focus I: Reformat Entire Dataset for Total Training\n",
    "After our analysis of the support vector machine (SVM) classifier, we move forward to analyzing the accuracy of classifications using random forests or random decision forests for classification.\n",
    "\n",
    "Random forests operate by constructing a multitude of decision tress at training time and outputting the class that is the mode of the classes. Rnadom decision forests correct for decision trees' habit of overfitting to their training set.\n",
    "\n",
    "First, we reformat the Entire Dataset for total model training across the dataset to analyze the best regularization strength, $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelazcona/miniconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning:\n",
      "\n",
      "Data with input dtype object was converted to float64 by the scale function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flag = False\n",
    "for year in play_years:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        teamNames = np.transpose( np.array( [teams[year]['team']] ) )\n",
    "        continue\n",
    "    teamNames = np.vstack( (teamNames, np.transpose( np.array( [teams[year]['team']] ) ) ) )\n",
    "X = np.hstack( ( teamNames, np.array(deepcopy(allTeamHist)) ) )\n",
    "X = pd.DataFrame(X, columns = [\"Team\"] + columns)\n",
    "\n",
    "del X['Team']\n",
    "del X['Playoff']\n",
    "del X['REB%']\n",
    "del X['PF']\n",
    "del X['TO']\n",
    "del X['OR']\n",
    "del X['FT%']\n",
    "\n",
    "y = list( deepcopy(allTeamHist['Playoff']) )\n",
    "Xs = preprocessing.scale(np.array(X))\n",
    "\n",
    "nsamp = Xs.shape[0]\n",
    "ntr = int(0.8*nsamp)\n",
    "nts = nsamp - ntr\n",
    "\n",
    "Xtr = Xs[:ntr,:]\n",
    "ytr = y[:ntr]\n",
    "\n",
    "Xts = Xs[ntr:,:]\n",
    "yts = y[ntr:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process V: Random Forest Classification\n",
    "### Focus II: Intialize Random Forest Model Instance and Test Seperate Regularization Strengths on Entire Datatset Prediction\n",
    "Afterwards, we intialize a random forst model instance and test our classifier across several numbers of trees to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_est_vals = np.logspace(1,3,15)\n",
    "num_est_vals = num_est_vals.ravel().tolist()\n",
    "for i in range(len(num_est_vals)):\n",
    "    num_est_vals[i] = int(num_est_vals[i])\n",
    "\n",
    "err = []\n",
    "\n",
    "err_min = 1\n",
    "\n",
    "flag = False\n",
    "for num_est in num_est_vals:\n",
    "    if not flag:\n",
    "        flag = True\n",
    "        est_min = num_est\n",
    "        \n",
    "    rfModel = RandomForestClassifier(n_estimators = num_est)\n",
    "    \n",
    "    rfModel.fit(Xs,y)\n",
    "    \n",
    "    y_hat = rfModel.predict(Xtr)\n",
    "    \n",
    "    err_i = np.mean(y_hat != ytr)\n",
    "    \n",
    "    err.append(err_i)\n",
    "    \n",
    "    if (err_min > err_i):\n",
    "        err_min = err_i\n",
    "        est_min = num_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process V: Random Forest Classification\n",
    "### Focus III: Tabulate & Analyze Entire Dataset Training Errors\n",
    "\n",
    "Next, we tabulate our results and analyze the errors based on the tree numbers on each of our Random Forest classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/40.embed\" height=\"530px\" width=\"500px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_est_valsArr = np.transpose( np.array([num_est_vals]))\n",
    "\n",
    "errArr = np.transpose( np.array([err]) )\n",
    "\n",
    "totAccTable = FF.create_table( pd.DataFrame( np.hstack((num_est_valsArr, errArr))\\\n",
    "                                            , columns = ['Number of Estimators (Trees)', 'error rate']) )\n",
    "\n",
    "totAccTable.layout.width = 500\n",
    "totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "totAccTable.layout.update({'title': 'Random Forest Classifier Error Rates'})\n",
    "py.iplot(totAccTable, filename = 'overRandomForestTable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-process V: Random Forest Classification\n",
    "### Focus IV: Use Random Forest Models with Minimal Errors to Progressively Predict Throughout NBA Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileTrainData(teamsDict, year):\n",
    "    flag = False\n",
    "    for i in range(1,year+1):\n",
    "        if not flag:\n",
    "            flag = True\n",
    "            Xtr = np.array(teamsDict[i])\n",
    "            continue\n",
    "        Xtr = np.vstack( (Xtr, np.array(teamsDict[i]) ) )\n",
    "    return Xtr\n",
    "    \n",
    "trainingFeatureSets = []\n",
    "trainingTargetSets = []\n",
    "for year in play_years[:-1]:\n",
    "    Xtr = compileTrainData(teamsDict, year)\n",
    "    ytr = deepcopy(Xtr[:,0])\n",
    "    Xtr = Xtr[:,1:]\n",
    "    \n",
    "    trainingFeatureSets.append(preprocessing.scale(Xtr))\n",
    "    trainingTargetSets.append(ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accRF = []\n",
    "for i, year in enumerate(play_years[1:]):\n",
    "    Xts = np.array(teamsDict[year])\n",
    "    yts = deepcopy(Xts[:,0])\n",
    "    Xts =  preprocessing.scale(Xts[:,1:])\n",
    "    \n",
    "    rfModel = RandomForestClassifier(est_min)\n",
    "    \n",
    "    rfModel.fit( trainingFeatureSets[i], trainingTargetSets[i] )\n",
    "        \n",
    "    yts_hat = rfModel.predict_proba(Xts)\n",
    "    \n",
    "    playoffTeams = np.array(teams[year]['team'])[np.where(np.array(yts) == True)]\n",
    "    \n",
    "    sortedPlayPred = np.argsort(yts_hat[:,1])\n",
    "    predictedTeams = np.array(teams[year]['team'])[sortedPlayPred[-16:]]\n",
    "    \n",
    "    corr = 0\n",
    "    i = 0\n",
    "    \n",
    "    for predict in predictedTeams:\n",
    "        i += 1\n",
    "        if predict in playoffTeams:\n",
    "            corr += 1\n",
    "    acc_i = float(corr)/i\n",
    "    \n",
    "    accRF.append(acc_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainYears = []\n",
    "testYears = []\n",
    "\n",
    "for curr in play_years[1:]:\n",
    "    trainYears.append( str(2001) + '-' + str(2000 + curr) )\n",
    "    testYears.append( str(2000 + curr) + '-' + str(2001 + curr) )\n",
    "\n",
    "trainYears = np.transpose(np.array([trainYears]))\n",
    "testYears = np.transpose(np.array([testYears]))\n",
    "\n",
    "acc_RF = np.transpose( np.array([accRF]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/42.embed\" height=\"500px\" width=\"750px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totAccTable = FF.create_table( pd.DataFrame( np.hstack((trainYears, testYears, acc_RF))\\\n",
    "                                            , columns = ['Train Years', 'Test NBA Season'\\\n",
    "                                                         , 'accuracy']) )\n",
    "\n",
    "totAccTable.layout.width = 750\n",
    "totAccTable.layout.margin.update({'t':75, 'l':50})\n",
    "totAccTable.layout.update({'title': 'Accuracy of Progressively-Trained Random Forest Model Over Each NBA Season'})\n",
    "py.iplot(totAccTable, filename = 'progAccRandomForestTable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion for NBA-Playoff Predictions\n",
    "\n",
    "Based on our results for the earlier seasons in the NBA, it makes sense to use the logistic regression classifiers for predicting NBA-Playoff contention, however we see that as we obtain more training data and try to predict some of the more recent NBA-Playoff contenders, the random forest classifier model's accuracy begins to level with that of the logistic regression classifiers. Therefore, we hypothesize that as we continue to obtain more data for the coming NBA seasons, the random forest classifier and logistic classifiers will continue to be the most accurate of the classifier models that we analyze in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~emanuelazcona/46.embed\" height=\"800px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalAcc = [accl1, accl2, acc, acc_rbf, acc_poly, acc_RFArr]\n",
    "names = ['l1-penalized logistic', 'l2-penalized logistic'\n",
    "         , 'unregularized logistic', 'radial basis SVM'\n",
    "         , 'polynomial SVM', 'random forest']\n",
    "\n",
    "data = []\n",
    "for currAcc, name in zip(totalAcc, names):\n",
    "    trace = go.Bar(\n",
    "                x = currAcc.ravel().tolist(),\n",
    "                y = teamYears,\n",
    "                orientation = 'h',\n",
    "                name = name\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "            title = 'Progressive Classifier Model Accuracies Throughout NBA Seasons',\n",
    "            autosize = True,\n",
    "            width = 800,\n",
    "            height = 800)\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "allAccPlot = py.iplot(fig, filename = 'All Model Acccuracies Throughout NBA Seasons')\n",
    "allAccPlot"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
